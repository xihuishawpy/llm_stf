{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c93eec-7640-4b13-90a2-a19c084ddcf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:21:51.589801Z",
     "iopub.status.busy": "2025-01-02T15:21:51.589497Z",
     "iopub.status.idle": "2025-01-02T15:21:55.329209Z",
     "shell.execute_reply": "2025-01-02T15:21:55.328706Z",
     "shell.execute_reply.started": "2025-01-02T15:21:51.589783Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'LLaMA-Factory'...\n",
      "remote: Enumerating objects: 323, done.\u001b[K\n",
      "remote: Counting objects: 100% (323/323), done.\u001b[K\n",
      "remote: Compressing objects: 100% (270/270), done.\u001b[K\n",
      "remote: Total 323 (delta 78), reused 131 (delta 39), pack-reused 0 (from 0)\u001b[K\n",
      "接收对象中: 100% (323/323), 8.98 MiB | 5.77 MiB/s, 完成.\n",
      "处理 delta 中: 100% (78/78), 完成.\n",
      "/mnt/workspace/LLaMA-Factory\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "%cd LLaMA-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40386c3-8809-4f6b-95e9-24911d58e2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:22:03.023992Z",
     "iopub.status.busy": "2025-01-02T15:22:03.023661Z",
     "iopub.status.idle": "2025-01-02T15:22:31.759881Z",
     "shell.execute_reply": "2025-01-02T15:22:31.759302Z",
     "shell.execute_reply.started": "2025-01-02T15:22:03.023965Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: accelerate 0.33.0\n",
      "Uninstalling accelerate-0.33.0:\n",
      "  Successfully uninstalled accelerate-0.33.0\n",
      "Found existing installation: vllm 0.5.1\n",
      "Uninstalling vllm-0.5.1:\n",
      "  Successfully uninstalled vllm-0.5.1\n",
      "Found existing installation: matplotlib 3.9.0\n",
      "Uninstalling matplotlib-3.9.0:\n",
      "  Successfully uninstalled matplotlib-3.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting llamafactory==0.9.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/70/45/44f0f72d1a0737e2b3f1fead3803fe2f24ae8345f0f38132eebefa0f4197/llamafactory-0.9.0-py3-none-any.whl (245 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (24.0)\n",
      "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (0.12.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (0.8.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (2.7.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (2.2.2)\n",
      "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (2.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (1.12.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (0.7.0)\n",
      "Collecting trl<=0.9.6,>=0.8.6\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a5/c3/6565c2c376a829f99da20d39c2912405195ec1fa6aae068dc45c46793e72/trl-0.9.6-py3-none-any.whl (245 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (1.26.3)\n",
      "Collecting accelerate<=0.33.0,>=0.30.1\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/15/33/b6b4ad5efa8b9f4275d4ed17ff8a44c97276171341ba565fdffb0e3dc5e8/accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: uvicorn in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (0.30.3)\n",
      "Collecting matplotlib>=3.7.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/09/5a/a113495110ae3e3395c72d82d7bc4802902e46dc797f6b041e572f195c56/matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets<=2.21.0,>=2.16.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (2.20.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (3.20.3)\n",
      "Collecting gradio>=4.0.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/64/cb/9bfce732279c48f06c64582f9444422e08d9d48466467d15c2842e3aef44/gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fire in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (0.6.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (6.0.1)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (0.111.1)\n",
      "Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (4.45.0.dev0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.0) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/site-packages (from accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/site-packages (from accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (0.24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (5.9.8)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (0.4.3)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (3.9.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (3.4.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (2.32.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (0.3.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (2024.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (17.0.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (4.66.4)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (0.6)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (0.70.16)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.9.0) (4.12.0)\n",
      "Collecting python-multipart>=0.0.18\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/45/58/38b5afbc1a800eeea951b9285d3912613f2603bdf897a4ab0f4bd7f405fc/python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.9.0) (0.27.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.9.0) (0.12.3)\n",
      "Collecting semantic-version~=2.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.9.0) (4.4.0)\n",
      "Collecting orjson~=3.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c2/41/58f73d6656f1c9d6e736549f36066ce16ba91e33a639c8cca278af09baf3/orjson-3.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/53/5d/65f40bd333463b3230b3a72d93873caaf49b0cbb5228598fafb75fcc5357/ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Collecting fastapi\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/52/b3/7e4df40e585df024fac2f80d1a2d579c854ac37109675db2b0cc22c0bb9e/fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.9.0) (2.1.5)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.9.0) (3.1.4)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Collecting aiofiles<24.0,>=22.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4d/c0/1108ad9f01567f66b3154063605b350b69c3c9366732e09e45f9fd0d1deb/safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Collecting ruff>=0.2.2\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1a/f6/52a2973ff108d74b5da706a573379eea160bece098f7cfa3f35dc4622710/ruff-0.8.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting huggingface-hub>=0.21.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/61/8c/fbdc0a88a622d9fa54e132d7bf3ee03ec602758658a2db5b339a65be2cfe/huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.9.0) (10.2.0)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6b/2c/a50484b035ee0e13ebb7a42391e391befbfc1b6a9ad5503e83badd182ada/starlette-0.45.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==1.5.2\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/69/ca/4d8ae560144a3e39b2a6d1848a5852c2822624506f9eccf90dabccd004bf/gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/site-packages (from gradio-client==1.5.2->gradio>=4.0.0->llamafactory==0.9.0) (12.0)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/96/00/2b325970b3060c7cecebab6d295afe763365822b1306a12eeab198f74323/starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.0) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.0) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.0) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.0) (3.1.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.0) (4.53.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.0) (1.2.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.0) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.0) (2024.1)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/site-packages (from pydantic->llamafactory==0.9.0) (2.18.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic->llamafactory==0.9.0) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.0) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/site-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.0) (0.19.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/site-packages (from trl<=0.9.6,>=0.8.6->llamafactory==0.9.0) (0.8.10)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/site-packages (from uvicorn->llamafactory==0.9.0) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/site-packages (from uvicorn->llamafactory==0.9.0) (8.1.7)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/site-packages (from fire->llamafactory==0.9.0) (2.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from fire->llamafactory==0.9.0) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.0) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.0) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.0) (1.2.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (23.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (6.0.5)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.0) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.0) (1.0.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.0) (3.3.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (1.12.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (3.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (12.6.68)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.0) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.0) (1.5.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/site-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.0) (1.7.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/site-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.0) (0.16)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.0) (2.18.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->llamafactory==0.9.0) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.0) (0.1.2)\n",
      "Installing collected packages: pydub, tomlkit, semantic-version, ruff, python-multipart, orjson, ffmpy, aiofiles, starlette, matplotlib, huggingface-hub, safehttpx, gradio-client, fastapi, gradio, accelerate, trl, llamafactory\n",
      "  Attempting uninstall: python-multipart\n",
      "    Found existing installation: python-multipart 0.0.9\n",
      "    Uninstalling python-multipart-0.0.9:\n",
      "      Successfully uninstalled python-multipart-0.0.9\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.37.2\n",
      "    Uninstalling starlette-0.37.2:\n",
      "      Successfully uninstalled starlette-0.37.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.24.2\n",
      "    Uninstalling huggingface-hub-0.24.2:\n",
      "      Successfully uninstalled huggingface-hub-0.24.2\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.111.1\n",
      "    Uninstalling fastapi-0.111.1:\n",
      "      Successfully uninstalled fastapi-0.111.1\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.10.1\n",
      "    Uninstalling trl-0.10.1:\n",
      "      Successfully uninstalled trl-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pai-easycv 0.11.6 requires timm==0.5.4, but you have timm 1.0.9 which is incompatible.\n",
      "optimum 1.21.4 requires transformers[sentencepiece]<4.44.0,>=4.29.0, but you have transformers 4.45.0.dev0 which is incompatible.\n",
      "lmdeploy 0.5.0 requires peft<=0.11.1, but you have peft 0.12.0 which is incompatible.\n",
      "easyrobust 0.2.4 requires timm==0.5.4, but you have timm 1.0.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.33.0 aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 huggingface-hub-0.27.0 llamafactory-0.9.0 matplotlib-3.10.0 orjson-3.10.13 pydub-0.25.1 python-multipart-0.0.20 ruff-0.8.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 trl-0.9.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y accelerate vllm matplotlib\n",
    "!pip install llamafactory==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44963da9-1629-4583-a068-c9df357875ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:22:31.761080Z",
     "iopub.status.busy": "2025-01-02T15:22:31.760821Z",
     "iopub.status.idle": "2025-01-02T15:22:32.295133Z",
     "shell.execute_reply": "2025-01-02T15:22:32.294609Z",
     "shell.execute_reply.started": "2025-01-02T15:22:31.761063Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-02 23:22:31--  https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/llama_factory/Qwen2-VL-History.zip\n",
      "正在解析主机 atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)... 47.101.88.43\n",
      "正在连接 atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)|47.101.88.43|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度： 7436378 (7.1M) [application/zip]\n",
      "正在保存至: ‘Qwen2-VL-History.zip’\n",
      "\n",
      "Qwen2-VL-History.zi 100%[===================>]   7.09M  --.-KB/s    用时 0.1s    \n",
      "\n",
      "2025-01-02 23:22:32 (63.7 MB/s) - 已保存 ‘Qwen2-VL-History.zip’ [7436378/7436378])\n",
      "\n",
      "Archive:  Qwen2-VL-History.zip\n",
      "  inflating: data/dataset_info.json  \n",
      "   creating: data/images/\n",
      "  inflating: data/images/instance_1712368925837795330.jpg  \n",
      "  inflating: data/images/instance_1575754532417236996.jpg  \n",
      "  inflating: data/images/instance_1583755072329805825.jpg  \n",
      "  inflating: data/images/instance_1609824244960653314.jpg  \n",
      "  inflating: data/images/instance_1575684349870796803.jpg  \n",
      "  inflating: data/images/instance_1712310957381910530.jpg  \n",
      "  inflating: data/images/instance_1575684349887574018.jpg  \n",
      "  inflating: data/images/instance_1605453554706870273.jpg  \n",
      "  inflating: data/images/instance_1575697898059919365.jpg  \n",
      "  inflating: data/images/instance_1605861397096361985.jpg  \n",
      "  inflating: data/images/instance_1579398113581395972.jpg  \n",
      "  inflating: data/images/instance_1579388661327261697.jpg  \n",
      "  inflating: data/images/instance_1712355420103901186.jpg  \n",
      "  inflating: data/images/instance_1605406510357213186.jpg  \n",
      "  inflating: data/images/instance_1575754532383682562.jpg  \n",
      "  inflating: data/images/instance_1634147576819822594.jpg  \n",
      "  inflating: data/images/instance_1712438235273048066.jpg  \n",
      "  inflating: data/images/instance_1588116956264853505.jpg  \n",
      "  inflating: data/images/instance_1579388661318873090.jpg  \n",
      "  inflating: data/images/instance_1594942441246486530.jpg  \n",
      "  inflating: data/images/instance_1712411007734722562.jpg  \n",
      "  inflating: data/images/instance_1792820301478404098.jpg  \n",
      "  inflating: data/images/instance_1588114992445583361.jpg  \n",
      "  inflating: data/images/instance_1712356537546436609.jpg  \n",
      "  inflating: data/images/instance_1603659751587115010.jpg  \n",
      "  inflating: data/images/instance_1584816943107469314.jpg  \n",
      "  inflating: data/images/instance_1603662836053110786.jpg  \n",
      "  inflating: data/images/instance_1585151302117158913.jpg  \n",
      "  inflating: data/images/instance_1585181488808259586.jpg  \n",
      "  inflating: data/images/instance_1645237409419964418.jpg  \n",
      "  inflating: data/images/instance_1598221987395727362.jpg  \n",
      "  inflating: data/images/instance_1579408762881503233.jpg  \n",
      "  inflating: data/images/instance_1586990758474346497.jpg  \n",
      "  inflating: data/images/instance_1579398113560424451.jpg  \n",
      "  inflating: data/images/instance_1712369377371398146.jpg  \n",
      "  inflating: data/images/instance_1575697898022170627.jpg  \n",
      "  inflating: data/images/instance_1575684349891768322.jpg  \n",
      "  inflating: data/images/instance_1712360200394113025.jpg  \n",
      "  inflating: data/images/instance_1579376278198349827.jpg  \n",
      "  inflating: data/images/instance_1579376278252875778.jpg  \n",
      "  inflating: data/images/instance_1609717271372034050.jpg  \n",
      "  inflating: data/images/instance_1588110120253976578.jpg  \n",
      "  inflating: data/images/instance_1579398113589784578.jpg  \n",
      "  inflating: data/images/instance_1638131855224549378.jpg  \n",
      "  inflating: data/images/instance_1712368307161919490.jpg  \n",
      "  inflating: data/images/instance_1583752643131535361.jpg  \n",
      "  inflating: data/images/instance_1712362888703901698.jpg  \n",
      "  inflating: data/images/instance_1712304288266584066.jpg  \n",
      "  inflating: data/images/instance_1588114119933882370.jpg  \n",
      "  inflating: data/images/instance_1712305779123552258.jpg  \n",
      "  inflating: data/images/instance_1605474945132982273.jpg  \n",
      "  inflating: data/images/instance_1552218853139910657.jpg  \n",
      "  inflating: data/images/instance_1541679966589616129.jpg  \n",
      "  inflating: data/images/instance_1579408762873114627.jpg  \n",
      "  inflating: data/images/instance_1712436279368429570.jpg  \n",
      "  inflating: data/images/instance_1642025622293786626.jpg  \n",
      "  inflating: data/images/instance_1641394053371736065.jpg  \n",
      "  inflating: data/images/instance_1638129274825814017.jpg  \n",
      "  inflating: data/images/instance_1579398113589784583.jpg  \n",
      "  inflating: data/images/instance_1712410705440849922.jpg  \n",
      "  inflating: data/images/instance_1598551736093569026.jpg  \n",
      "  inflating: data/images/instance_1579376278118658052.jpg  \n",
      "  inflating: data/images/instance_1712437520343293954.jpg  \n",
      "  inflating: data/images/instance_1579376275388166145.jpg  \n",
      "  inflating: data/images/instance_1575005049068777475.jpg  \n",
      "  inflating: data/images/instance_1712415517955645441.jpg  \n",
      "  inflating: data/images/instance_1712303696378503170.jpg  \n",
      "  inflating: data/images/instance_1585212135388016642.jpg  \n",
      "  inflating: data/images/instance_1712353819591049217.jpg  \n",
      "  inflating: data/images/instance_1603662164888973314.jpg  \n",
      "  inflating: data/images/instance_1609831285456433153.jpg  \n",
      "  inflating: data/images/instance_1586286817218457602.jpg  \n",
      "  inflating: data/images/instance_1609831567124918274.jpg  \n",
      "  inflating: data/images/instance_1579388661302095873.jpg  \n",
      "  inflating: data/images/instance_1712366770942812161.jpg  \n",
      "  inflating: data/images/instance_1589506784390868993.jpg  \n",
      "  inflating: data/images/instance_1575684349858213889.jpg  \n",
      "  inflating: data/images/instance_1712408837058772993.jpg  \n",
      "  inflating: data/images/instance_1579398113556230146.jpg  \n",
      "  inflating: data/images/instance_1579408762898280451.jpg  \n",
      "  inflating: data/images/instance_1594943407861592066.jpg  \n",
      "  inflating: data/images/instance_1552220458182610945.jpg  \n",
      "  inflating: data/images/instance_1712390636436103170.jpg  \n",
      "  inflating: data/images/instance_1605474594426253313.jpg  \n",
      "  inflating: data/images/instance_1575697898005393409.jpg  \n",
      "  inflating: data/train.json         \n"
     ]
    }
   ],
   "source": [
    "!wget https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/llama_factory/Qwen2-VL-History.zip\n",
    "!mv data rawdata && unzip Qwen2-VL-History.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa4a41-0a9c-4f9f-8ae6-adaa387f2f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:22:42.474422Z",
     "iopub.status.busy": "2025-01-02T15:22:42.474111Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-02 23:22:53,639] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: 没有那个文件或目录\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
      "/usr/local/lib/python3.10/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n",
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "[2025-01-02 23:24:08,763] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
      "01/02/2025 23:24:12 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n",
      "2025-01-02 23:24:12,668 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "Downloading [chat_template.json]: 100%|████| 1.03k/1.03k [00:00<00:00, 1.28kB/s]\n",
      "Downloading [config.json]: 100%|███████████| 1.17k/1.17k [00:00<00:00, 1.61kB/s]\n",
      "Downloading [configuration.json]: 100%|███████| 76.0/76.0 [00:00<00:00, 85.7B/s]\n",
      "Downloading [generation_config.json]: 100%|██████| 272/272 [00:00<00:00, 379B/s]\n",
      "Downloading [LICENSE]: 100%|███████████████| 11.1k/11.1k [00:00<00:00, 13.0kB/s]\n",
      "Downloading [merges.txt]: 100%|████████████| 1.59M/1.59M [00:00<00:00, 1.84MB/s]\n",
      "Downloading [model-00001-of-00002.safetensors]: 100%|█| 3.71G/3.71G [00:12<00:00\n",
      "Downloading [model-00002-of-00002.safetensors]: 100%|█| 410M/410M [00:03<00:00, \n",
      "Downloading [model.safetensors.index.json]: 100%|█| 55.1k/55.1k [00:01<00:00, 46\n",
      "Downloading [preprocessor_config.json]: 100%|████| 347/347 [00:00<00:00, 425B/s]\n",
      "Downloading [README.md]: 100%|█████████████| 16.2k/16.2k [00:00<00:00, 17.6kB/s]\n",
      "Downloading [tokenizer.json]: 100%|████████| 6.70M/6.70M [00:00<00:00, 7.56MB/s]\n",
      "Downloading [tokenizer_config.json]: 100%|█| 4.09k/4.09k [00:00<00:00, 4.68kB/s]\n",
      "Downloading [vocab.json]: 100%|████████████| 2.65M/2.65M [00:00<00:00, 3.25MB/s]\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:24:51,947 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:24:51,949 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:51,951 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:51,951 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:51,951 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:51,951 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:51,951 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:51,951 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:24:52,123 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:24:52,123 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:24:52,125 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:429] 2025-01-02 23:24:52,126 >> Image processor Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:52,126 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:52,126 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:52,126 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:52,126 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:52,126 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:24:52,126 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:24:52,283 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|processing_utils.py:722] 2025-01-02 23:24:52,510 >> Processor Qwen2VLProcessor:\n",
      "- image_processor: Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "- tokenizer: Qwen2TokenizerFast(name_or_path='/mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "\n",
      "{\n",
      "  \"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\",\n",
      "  \"processor_class\": \"Qwen2VLProcessor\"\n",
      "}\n",
      "\n",
      "01/02/2025 23:24:52 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
      "01/02/2025 23:24:52 - INFO - llamafactory.data.loader - Loading dataset train.json...\n",
      "Generating train split: 261 examples [00:00, 4773.97 examples/s]\n",
      "Converting format of dataset (num_proc=16): 100%|█| 261/261 [00:00<00:00, 1441.8\n",
      "Running tokenizer on dataset (num_proc=16): 100%|█| 261/261 [00:02<00:00, 90.67 \n",
      "training example:\n",
      "input_ids:\n",
      "[151644, 8948, 198, 56568, 101909, 16744, 99394, 104058, 37945, 108487, 101131, 29490, 102104, 20002, 101080, 103936, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 104169, 99526, 99526, 99487, 100413, 151645, 198, 151644, 77091, 198, 2, 53040, 52853, 29991, 198, 99315, 27091, 100526, 100658, 103210, 198, 2, 220, 100177, 198, 16628, 99385, 31548, 100177, 198, 2, 69674, 62922, 198, 100658, 31548, 198, 2, 80090, 114, 50366, 100008, 198, 104649, 104645, 93823, 198, 2, 58230, 118, 101490, 198, 44636, 17, 15, 13, 21, 105887, 3837, 99845, 16, 18, 13, 16, 105887, 3837, 99696, 15, 13, 19, 105887, 198, 2, 65727, 118, 72990, 20450, 198, 16, 24, 21, 19, 7948, 198, 2, 65727, 118, 101962, 27442, 198, 101521, 112634, 33447, 115640, 80942, 77128, 57811, 198, 2, 64388, 117, 99543, 53481, 198, 43268, 99483, 3837, 115230, 17714, 99315, 17340, 99369, 110503, 64355, 65101, 3837, 64355, 100469, 99704, 99853, 3837, 101488, 112419, 45861, 28291, 3837, 99246, 101344, 104542, 30440, 100975, 24968, 115230, 17714, 105235, 82699, 53938, 99579, 17447, 21596, 99315, 17340, 99704, 99853, 108565, 3837, 105190, 99627, 99398, 198, 2, 8908, 109, 94, 99543, 100240, 198, 106411, 104561, 54658, 100830, 105430, 151645]\n",
      "inputs:\n",
      "<|im_start|>system\n",
      "你是一个文博工作人员，请严谨认真地回答用户提出的问题<|im_end|>\n",
      "<|im_start|>user\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>给我讲讲这个东西<|im_end|>\n",
      "<|im_start|>assistant\n",
      "# 文物名称\n",
      "神面纹玉戚\n",
      "# 时代\n",
      "新石器时代\n",
      "# 类别\n",
      "玉器\n",
      "# 收藏机构\n",
      "山西博物院\n",
      "# 尺寸\n",
      "高20.6厘米，宽13.1厘米，厚0.4厘米\n",
      "# 出土时间\n",
      "1964年\n",
      "# 出土地点\n",
      "黎城县后庄村广志山\n",
      "# 特征描述\n",
      "线刻，一侧为神人半侧面头像，头戴冠饰，披拂长发，眼眉清晰可辨；一侧为一方形台座上置神人冠饰的形象，神秘威严\n",
      "# 象征意义\n",
      "象征军事统帅权力<|im_end|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, 53040, 52853, 29991, 198, 99315, 27091, 100526, 100658, 103210, 198, 2, 220, 100177, 198, 16628, 99385, 31548, 100177, 198, 2, 69674, 62922, 198, 100658, 31548, 198, 2, 80090, 114, 50366, 100008, 198, 104649, 104645, 93823, 198, 2, 58230, 118, 101490, 198, 44636, 17, 15, 13, 21, 105887, 3837, 99845, 16, 18, 13, 16, 105887, 3837, 99696, 15, 13, 19, 105887, 198, 2, 65727, 118, 72990, 20450, 198, 16, 24, 21, 19, 7948, 198, 2, 65727, 118, 101962, 27442, 198, 101521, 112634, 33447, 115640, 80942, 77128, 57811, 198, 2, 64388, 117, 99543, 53481, 198, 43268, 99483, 3837, 115230, 17714, 99315, 17340, 99369, 110503, 64355, 65101, 3837, 64355, 100469, 99704, 99853, 3837, 101488, 112419, 45861, 28291, 3837, 99246, 101344, 104542, 30440, 100975, 24968, 115230, 17714, 105235, 82699, 53938, 99579, 17447, 21596, 99315, 17340, 99704, 99853, 108565, 3837, 105190, 99627, 99398, 198, 2, 8908, 109, 94, 99543, 100240, 198, 106411, 104561, 54658, 100830, 105430, 151645]\n",
      "labels:\n",
      "# 文物名称\n",
      "神面纹玉戚\n",
      "# 时代\n",
      "新石器时代\n",
      "# 类别\n",
      "玉器\n",
      "# 收藏机构\n",
      "山西博物院\n",
      "# 尺寸\n",
      "高20.6厘米，宽13.1厘米，厚0.4厘米\n",
      "# 出土时间\n",
      "1964年\n",
      "# 出土地点\n",
      "黎城县后庄村广志山\n",
      "# 特征描述\n",
      "线刻，一侧为神人半侧面头像，头戴冠饰，披拂长发，眼眉清晰可辨；一侧为一方形台座上置神人冠饰的形象，神秘威严\n",
      "# 象征意义\n",
      "象征军事统帅权力<|im_end|>\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:24:56,685 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:24:56,687 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3671] 2025-01-02 23:24:56,702 >> loading weights file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1607] 2025-01-02 23:24:56,703 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:24:56,704 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.06it/s]\n",
      "[INFO|modeling_utils.py:4503] 2025-01-02 23:24:59,011 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:4511] 2025-01-02 23:24:59,011 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:1013] 2025-01-02 23:24:59,015 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/generation_config.json\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:24:59,015 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.01,\n",
      "  \"top_k\": 1,\n",
      "  \"top_p\": 0.001\n",
      "}\n",
      "\n",
      "01/02/2025 23:24:59 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "01/02/2025 23:24:59 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "01/02/2025 23:24:59 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "01/02/2025 23:24:59 - INFO - llamafactory.model.adapter - Fine-tuning method: Full\n",
      "01/02/2025 23:24:59 - INFO - llamafactory.model.loader - trainable params: 1,543,714,304 || all params: 2,208,985,600 || trainable%: 69.8834\n",
      "[INFO|trainer.py:667] 2025-01-02 23:24:59,127 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2182] 2025-01-02 23:24:59,468 >> ***** Running training *****\n",
      "[INFO|trainer.py:2183] 2025-01-02 23:24:59,468 >>   Num examples = 261\n",
      "[INFO|trainer.py:2184] 2025-01-02 23:24:59,468 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2185] 2025-01-02 23:24:59,468 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2188] 2025-01-02 23:24:59,469 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2189] 2025-01-02 23:24:59,469 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:2190] 2025-01-02 23:24:59,469 >>   Total optimization steps = 650\n",
      "[INFO|trainer.py:2191] 2025-01-02 23:24:59,470 >>   Number of trainable parameters = 1,543,714,304\n",
      "  0%|                                                   | 0/650 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llamafactory/cli.py\", line 111, in main\n",
      "    run_exp()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llamafactory/train/tuner.py\", line 50, in run_exp\n",
      "    run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llamafactory/train/sft/workflow.py\", line 96, in run_sft\n",
      "    train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/transformers/trainer.py\", line 1991, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/transformers/trainer.py\", line 2327, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/transformers/trainer.py\", line 3419, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/transformers/trainer.py\", line 3466, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 819, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py\", line 1584, in forward\n",
      "    inputs_embeds[image_mask] = image_embeds\n",
      "RuntimeError: Index put requires the source and destination dtypes match, got Float for the destination and BFloat16 for the source.\n",
      "  0%|                                                   | 0/650 [00:01<?, ?it/s]\n",
      "[2025-01-02 23:25:24,202] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
      "01/02/2025 23:25:27 - WARNING - llamafactory.hparams.parser - We recommend enable mixed precision training.\n",
      "01/02/2025 23:25:27 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n",
      "2025-01-02 23:25:28,082 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:25:28,383 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:25:28,385 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,386 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,386 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,386 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,386 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,386 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,386 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:25:28,547 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:25:28,548 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:25:28,549 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:429] 2025-01-02 23:25:28,549 >> Image processor Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,550 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,550 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,550 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,550 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,550 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:25:28,550 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:25:28,706 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|processing_utils.py:722] 2025-01-02 23:25:28,938 >> Processor Qwen2VLProcessor:\n",
      "- image_processor: Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "- tokenizer: Qwen2TokenizerFast(name_or_path='/mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "\n",
      "{\n",
      "  \"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\",\n",
      "  \"processor_class\": \"Qwen2VLProcessor\"\n",
      "}\n",
      "\n",
      "01/02/2025 23:25:28 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
      "01/02/2025 23:25:28 - INFO - llamafactory.data.loader - Loading dataset train.json...\n",
      "training example:\n",
      "input_ids:\n",
      "[151644, 8948, 198, 56568, 101909, 16744, 99394, 104058, 37945, 108487, 101131, 29490, 102104, 20002, 101080, 103936, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 104169, 99526, 99526, 99487, 100413, 151645, 198, 151644, 77091, 198, 2, 53040, 52853, 29991, 198, 99315, 27091, 100526, 100658, 103210, 198, 2, 220, 100177, 198, 16628, 99385, 31548, 100177, 198, 2, 69674, 62922, 198, 100658, 31548, 198, 2, 80090, 114, 50366, 100008, 198, 104649, 104645, 93823, 198, 2, 58230, 118, 101490, 198, 44636, 17, 15, 13, 21, 105887, 3837, 99845, 16, 18, 13, 16, 105887, 3837, 99696, 15, 13, 19, 105887, 198, 2, 65727, 118, 72990, 20450, 198, 16, 24, 21, 19, 7948, 198, 2, 65727, 118, 101962, 27442, 198, 101521, 112634, 33447, 115640, 80942, 77128, 57811, 198, 2, 64388, 117, 99543, 53481, 198, 43268, 99483, 3837, 115230, 17714, 99315, 17340, 99369, 110503, 64355, 65101, 3837, 64355, 100469, 99704, 99853, 3837, 101488, 112419, 45861, 28291, 3837, 99246, 101344, 104542, 30440, 100975, 24968, 115230, 17714, 105235, 82699, 53938, 99579, 17447, 21596, 99315, 17340, 99704, 99853, 108565, 3837, 105190, 99627, 99398, 198, 2, 8908, 109, 94, 99543, 100240, 198, 106411, 104561, 54658, 100830, 105430, 151645]\n",
      "inputs:\n",
      "<|im_start|>system\n",
      "你是一个文博工作人员，请严谨认真地回答用户提出的问题<|im_end|>\n",
      "<|im_start|>user\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>给我讲讲这个东西<|im_end|>\n",
      "<|im_start|>assistant\n",
      "# 文物名称\n",
      "神面纹玉戚\n",
      "# 时代\n",
      "新石器时代\n",
      "# 类别\n",
      "玉器\n",
      "# 收藏机构\n",
      "山西博物院\n",
      "# 尺寸\n",
      "高20.6厘米，宽13.1厘米，厚0.4厘米\n",
      "# 出土时间\n",
      "1964年\n",
      "# 出土地点\n",
      "黎城县后庄村广志山\n",
      "# 特征描述\n",
      "线刻，一侧为神人半侧面头像，头戴冠饰，披拂长发，眼眉清晰可辨；一侧为一方形台座上置神人冠饰的形象，神秘威严\n",
      "# 象征意义\n",
      "象征军事统帅权力<|im_end|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, 53040, 52853, 29991, 198, 99315, 27091, 100526, 100658, 103210, 198, 2, 220, 100177, 198, 16628, 99385, 31548, 100177, 198, 2, 69674, 62922, 198, 100658, 31548, 198, 2, 80090, 114, 50366, 100008, 198, 104649, 104645, 93823, 198, 2, 58230, 118, 101490, 198, 44636, 17, 15, 13, 21, 105887, 3837, 99845, 16, 18, 13, 16, 105887, 3837, 99696, 15, 13, 19, 105887, 198, 2, 65727, 118, 72990, 20450, 198, 16, 24, 21, 19, 7948, 198, 2, 65727, 118, 101962, 27442, 198, 101521, 112634, 33447, 115640, 80942, 77128, 57811, 198, 2, 64388, 117, 99543, 53481, 198, 43268, 99483, 3837, 115230, 17714, 99315, 17340, 99369, 110503, 64355, 65101, 3837, 64355, 100469, 99704, 99853, 3837, 101488, 112419, 45861, 28291, 3837, 99246, 101344, 104542, 30440, 100975, 24968, 115230, 17714, 105235, 82699, 53938, 99579, 17447, 21596, 99315, 17340, 99704, 99853, 108565, 3837, 105190, 99627, 99398, 198, 2, 8908, 109, 94, 99543, 100240, 198, 106411, 104561, 54658, 100830, 105430, 151645]\n",
      "labels:\n",
      "# 文物名称\n",
      "神面纹玉戚\n",
      "# 时代\n",
      "新石器时代\n",
      "# 类别\n",
      "玉器\n",
      "# 收藏机构\n",
      "山西博物院\n",
      "# 尺寸\n",
      "高20.6厘米，宽13.1厘米，厚0.4厘米\n",
      "# 出土时间\n",
      "1964年\n",
      "# 出土地点\n",
      "黎城县后庄村广志山\n",
      "# 特征描述\n",
      "线刻，一侧为神人半侧面头像，头戴冠饰，披拂长发，眼眉清晰可辨；一侧为一方形台座上置神人冠饰的形象，神秘威严\n",
      "# 象征意义\n",
      "象征军事统帅权力<|im_end|>\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:25:30,060 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:25:30,062 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3671] 2025-01-02 23:25:30,069 >> loading weights file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1607] 2025-01-02 23:25:30,069 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:25:30,070 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.77it/s]\n",
      "[INFO|modeling_utils.py:4503] 2025-01-02 23:25:31,628 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:4511] 2025-01-02 23:25:31,628 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:1013] 2025-01-02 23:25:31,633 >> loading configuration file /mnt/workspace/.cache/modelscope/hub/qwen/Qwen2-VL-2B-Instruct/generation_config.json\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:25:31,633 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.01,\n",
      "  \"top_k\": 1,\n",
      "  \"top_p\": 0.001\n",
      "}\n",
      "\n",
      "01/02/2025 23:25:31 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "01/02/2025 23:25:31 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "01/02/2025 23:25:31 - INFO - llamafactory.model.adapter - Pure bf16 / BAdam detected, remaining trainable params in half precision.\n",
      "01/02/2025 23:25:31 - INFO - llamafactory.model.adapter - Fine-tuning method: Full\n",
      "01/02/2025 23:25:31 - INFO - llamafactory.model.loader - trainable params: 1,543,714,304 || all params: 2,208,985,600 || trainable%: 69.8834\n",
      "[INFO|trainer.py:2182] 2025-01-02 23:25:31,939 >> ***** Running training *****\n",
      "[INFO|trainer.py:2183] 2025-01-02 23:25:31,939 >>   Num examples = 261\n",
      "[INFO|trainer.py:2184] 2025-01-02 23:25:31,939 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2185] 2025-01-02 23:25:31,939 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2188] 2025-01-02 23:25:31,939 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2189] 2025-01-02 23:25:31,939 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:2190] 2025-01-02 23:25:31,939 >>   Total optimization steps = 650\n",
      "[INFO|trainer.py:2191] 2025-01-02 23:25:31,941 >>   Number of trainable parameters = 1,543,714,304\n",
      "  1%|▎                                          | 5/650 [00:06<12:28,  1.16s/it]01/02/2025 23:25:38 - INFO - llamafactory.train.callbacks - {'loss': 2.5990, 'learning_rate': 9.9985e-06, 'epoch': 0.08, 'throughput': 1771.14}\n",
      "{'loss': 2.599, 'grad_norm': 14.25, 'learning_rate': 9.998540070400966e-06, 'epoch': 0.08, 'num_input_tokens_seen': 11184}\n",
      "  2%|▋                                         | 10/650 [00:11<12:04,  1.13s/it]01/02/2025 23:25:43 - INFO - llamafactory.train.callbacks - {'loss': 2.3942, 'learning_rate': 9.9942e-06, 'epoch': 0.15, 'throughput': 1783.88}\n",
      "{'loss': 2.3942, 'grad_norm': 9.9375, 'learning_rate': 9.994161134161635e-06, 'epoch': 0.15, 'num_input_tokens_seen': 21504}\n",
      "  2%|▉                                         | 15/650 [00:17<12:13,  1.16s/it]01/02/2025 23:25:49 - INFO - llamafactory.train.callbacks - {'loss': 2.4668, 'learning_rate': 9.9869e-06, 'epoch': 0.23, 'throughput': 1812.14}\n",
      "{'loss': 2.4668, 'grad_norm': 13.125, 'learning_rate': 9.986865748457457e-06, 'epoch': 0.23, 'num_input_tokens_seen': 32480}\n",
      "  3%|█▎                                        | 20/650 [00:23<11:58,  1.14s/it]01/02/2025 23:25:55 - INFO - llamafactory.train.callbacks - {'loss': 2.4928, 'learning_rate': 9.9767e-06, 'epoch': 0.31, 'throughput': 1822.44}\n",
      "{'loss': 2.4928, 'grad_norm': 11.0, 'learning_rate': 9.976658173588244e-06, 'epoch': 0.31, 'num_input_tokens_seen': 42848}\n",
      "  4%|█▌                                        | 25/650 [00:29<12:14,  1.17s/it]01/02/2025 23:26:01 - INFO - llamafactory.train.callbacks - {'loss': 2.4238, 'learning_rate': 9.9635e-06, 'epoch': 0.38, 'throughput': 1835.54}\n",
      "{'loss': 2.4238, 'grad_norm': 9.1875, 'learning_rate': 9.96354437049027e-06, 'epoch': 0.38, 'num_input_tokens_seen': 53568}\n",
      "  5%|█▉                                        | 30/650 [00:34<12:17,  1.19s/it]01/02/2025 23:26:06 - INFO - llamafactory.train.callbacks - {'loss': 2.3136, 'learning_rate': 9.9475e-06, 'epoch': 0.46, 'throughput': 1849.9}\n",
      "{'loss': 2.3136, 'grad_norm': 9.5, 'learning_rate': 9.947531997255256e-06, 'epoch': 0.46, 'num_input_tokens_seen': 64784}\n",
      "  5%|██▎                                       | 35/650 [00:40<11:54,  1.16s/it]01/02/2025 23:26:12 - INFO - llamafactory.train.callbacks - {'loss': 2.3576, 'learning_rate': 9.9286e-06, 'epoch': 0.53, 'throughput': 1858.45}\n",
      "{'loss': 2.3576, 'grad_norm': 10.3125, 'learning_rate': 9.928630404658255e-06, 'epoch': 0.53, 'num_input_tokens_seen': 75584}\n",
      "  6%|██▌                                       | 40/650 [00:46<11:49,  1.16s/it]01/02/2025 23:26:18 - INFO - llamafactory.train.callbacks - {'loss': 2.2293, 'learning_rate': 9.9069e-06, 'epoch': 0.61, 'throughput': 1862.78}\n",
      "{'loss': 2.2293, 'grad_norm': 11.4375, 'learning_rate': 9.906850630697068e-06, 'epoch': 0.61, 'num_input_tokens_seen': 86896}\n",
      "  7%|██▉                                       | 45/650 [00:51<10:54,  1.08s/it]01/02/2025 23:26:24 - INFO - llamafactory.train.callbacks - {'loss': 2.1272, 'learning_rate': 9.8822e-06, 'epoch': 0.69, 'throughput': 1866.31}\n",
      "{'loss': 2.1272, 'grad_norm': 9.625, 'learning_rate': 9.882205394146362e-06, 'epoch': 0.69, 'num_input_tokens_seen': 97216}\n",
      "  8%|███▏                                      | 50/650 [00:57<11:52,  1.19s/it]01/02/2025 23:26:30 - INFO - llamafactory.train.callbacks - {'loss': 2.3164, 'learning_rate': 9.8547e-06, 'epoch': 0.76, 'throughput': 1869.52}\n",
      "{'loss': 2.3164, 'grad_norm': 9.875, 'learning_rate': 9.854709087130261e-06, 'epoch': 0.76, 'num_input_tokens_seen': 108544}\n",
      "  8%|███▌                                      | 55/650 [01:03<12:00,  1.21s/it]01/02/2025 23:26:35 - INFO - llamafactory.train.callbacks - {'loss': 2.2246, 'learning_rate': 9.8244e-06, 'epoch': 0.84, 'throughput': 1875.46}\n",
      "{'loss': 2.2246, 'grad_norm': 9.6875, 'learning_rate': 9.824377766717758e-06, 'epoch': 0.84, 'num_input_tokens_seen': 120048}\n",
      "  9%|███▉                                      | 60/650 [01:10<12:40,  1.29s/it]01/02/2025 23:26:42 - INFO - llamafactory.train.callbacks - {'loss': 2.1397, 'learning_rate': 9.7912e-06, 'epoch': 0.92, 'throughput': 1859.58}\n",
      "{'loss': 2.1397, 'grad_norm': 9.1875, 'learning_rate': 9.791229145545832e-06, 'epoch': 0.92, 'num_input_tokens_seen': 131056}\n",
      " 10%|████▏                                     | 65/650 [01:16<12:30,  1.28s/it]01/02/2025 23:26:48 - INFO - llamafactory.train.callbacks - {'loss': 2.2032, 'learning_rate': 9.7553e-06, 'epoch': 0.99, 'throughput': 1860.7}\n",
      "{'loss': 2.2032, 'grad_norm': 9.9375, 'learning_rate': 9.755282581475769e-06, 'epoch': 0.99, 'num_input_tokens_seen': 143152}\n",
      " 11%|████▌                                     | 70/650 [01:22<11:17,  1.17s/it]01/02/2025 23:26:54 - INFO - llamafactory.train.callbacks - {'loss': 2.0715, 'learning_rate': 9.7166e-06, 'epoch': 1.07, 'throughput': 1855.36}\n",
      "{'loss': 2.0715, 'grad_norm': 11.875, 'learning_rate': 9.716559066288716e-06, 'epoch': 1.07, 'num_input_tokens_seen': 153184}\n",
      " 12%|████▊                                     | 75/650 [01:28<11:03,  1.15s/it]01/02/2025 23:27:00 - INFO - llamafactory.train.callbacks - {'loss': 1.9839, 'learning_rate': 9.6751e-06, 'epoch': 1.15, 'throughput': 1857.53}\n",
      "{'loss': 1.9839, 'grad_norm': 9.6875, 'learning_rate': 9.675081213427076e-06, 'epoch': 1.15, 'num_input_tokens_seen': 164224}\n",
      " 12%|█████▏                                    | 80/650 [01:34<10:58,  1.16s/it]01/02/2025 23:27:06 - INFO - llamafactory.train.callbacks - {'loss': 1.8883, 'learning_rate': 9.6309e-06, 'epoch': 1.22, 'throughput': 1856.64}\n",
      "{'loss': 1.8883, 'grad_norm': 9.875, 'learning_rate': 9.630873244788884e-06, 'epoch': 1.22, 'num_input_tokens_seen': 175184}\n",
      " 13%|█████▍                                    | 85/650 [01:39<10:33,  1.12s/it]01/02/2025 23:27:11 - INFO - llamafactory.train.callbacks - {'loss': 2.0308, 'learning_rate': 9.5840e-06, 'epoch': 1.30, 'throughput': 1857.44}\n",
      "{'loss': 2.0308, 'grad_norm': 9.6875, 'learning_rate': 9.583960976582914e-06, 'epoch': 1.3, 'num_input_tokens_seen': 185504}\n",
      " 14%|█████▊                                    | 90/650 [01:45<11:08,  1.19s/it]01/02/2025 23:27:17 - INFO - llamafactory.train.callbacks - {'loss': 2.0109, 'learning_rate': 9.5344e-06, 'epoch': 1.37, 'throughput': 1860.6}\n",
      "{'loss': 2.0109, 'grad_norm': 9.75, 'learning_rate': 9.534371804252727e-06, 'epoch': 1.37, 'num_input_tokens_seen': 197232}\n",
      " 15%|██████▏                                   | 95/650 [01:51<11:08,  1.21s/it]01/02/2025 23:27:23 - INFO - llamafactory.train.callbacks - {'loss': 1.9736, 'learning_rate': 9.4821e-06, 'epoch': 1.45, 'throughput': 1860.66}\n",
      "{'loss': 1.9736, 'grad_norm': 11.4375, 'learning_rate': 9.48213468647852e-06, 'epoch': 1.45, 'num_input_tokens_seen': 208288}\n",
      " 15%|██████▎                                  | 100/650 [01:57<10:39,  1.16s/it]01/02/2025 23:27:29 - INFO - llamafactory.train.callbacks - {'loss': 1.9175, 'learning_rate': 9.4273e-06, 'epoch': 1.53, 'throughput': 1857.86}\n",
      "{'loss': 1.9175, 'grad_norm': 12.125, 'learning_rate': 9.427280128266049e-06, 'epoch': 1.53, 'num_input_tokens_seen': 218944}\n",
      " 16%|██████▌                                  | 105/650 [02:03<11:38,  1.28s/it]01/02/2025 23:27:35 - INFO - llamafactory.train.callbacks - {'loss': 2.0725, 'learning_rate': 9.3698e-06, 'epoch': 1.60, 'throughput': 1862.07}\n",
      "{'loss': 2.0725, 'grad_norm': 10.0, 'learning_rate': 9.36984016313259e-06, 'epoch': 1.6, 'num_input_tokens_seen': 230928}\n",
      " 17%|██████▉                                  | 110/650 [02:10<11:10,  1.24s/it]01/02/2025 23:27:42 - INFO - llamafactory.train.callbacks - {'loss': 2.1503, 'learning_rate': 9.3098e-06, 'epoch': 1.68, 'throughput': 1865.69}\n",
      "{'loss': 2.1503, 'grad_norm': 9.8125, 'learning_rate': 9.309848334400247e-06, 'epoch': 1.68, 'num_input_tokens_seen': 242960}\n",
      " 18%|███████▎                                 | 115/650 [02:15<09:57,  1.12s/it]01/02/2025 23:27:47 - INFO - llamafactory.train.callbacks - {'loss': 1.9068, 'learning_rate': 9.2473e-06, 'epoch': 1.76, 'throughput': 1865.04}\n",
      "{'loss': 1.9068, 'grad_norm': 11.1875, 'learning_rate': 9.247339675607606e-06, 'epoch': 1.76, 'num_input_tokens_seen': 253440}\n",
      " 18%|███████▌                                 | 120/650 [02:21<10:00,  1.13s/it]01/02/2025 23:27:53 - INFO - llamafactory.train.callbacks - {'loss': 2.0101, 'learning_rate': 9.1824e-06, 'epoch': 1.83, 'throughput': 1863.66}\n",
      "{'loss': 2.0101, 'grad_norm': 10.625, 'learning_rate': 9.182350690051134e-06, 'epoch': 1.83, 'num_input_tokens_seen': 264192}\n",
      " 19%|███████▉                                 | 125/650 [02:28<11:04,  1.27s/it]01/02/2025 23:28:00 - INFO - llamafactory.train.callbacks - {'loss': 1.9263, 'learning_rate': 9.1149e-06, 'epoch': 1.91, 'throughput': 1863.65}\n",
      "{'loss': 1.9263, 'grad_norm': 8.9375, 'learning_rate': 9.114919329468283e-06, 'epoch': 1.91, 'num_input_tokens_seen': 276096}\n",
      " 20%|████████▏                                | 130/650 [02:33<10:05,  1.17s/it]01/02/2025 23:28:05 - INFO - llamafactory.train.callbacks - {'loss': 1.9073, 'learning_rate': 9.0451e-06, 'epoch': 1.98, 'throughput': 1862.2}\n",
      "{'loss': 1.9073, 'grad_norm': 10.875, 'learning_rate': 9.045084971874738e-06, 'epoch': 1.98, 'num_input_tokens_seen': 286416}\n",
      " 21%|████████▌                                | 135/650 [02:39<10:14,  1.19s/it]01/02/2025 23:28:11 - INFO - llamafactory.train.callbacks - {'loss': 1.9182, 'learning_rate': 8.9729e-06, 'epoch': 2.06, 'throughput': 1862.59}\n",
      "{'loss': 1.9182, 'grad_norm': 9.3125, 'learning_rate': 8.972888398568772e-06, 'epoch': 2.06, 'num_input_tokens_seen': 297352}\n",
      " 22%|████████▊                                | 140/650 [02:45<10:47,  1.27s/it]01/02/2025 23:28:17 - INFO - llamafactory.train.callbacks - {'loss': 1.8094, 'learning_rate': 8.8984e-06, 'epoch': 2.14, 'throughput': 1862.67}\n",
      "{'loss': 1.8094, 'grad_norm': 9.1875, 'learning_rate': 8.898371770316113e-06, 'epoch': 2.14, 'num_input_tokens_seen': 308984}\n",
      " 22%|█████████▏                               | 145/650 [02:51<09:36,  1.14s/it]01/02/2025 23:28:23 - INFO - llamafactory.train.callbacks - {'loss': 1.7535, 'learning_rate': 8.8216e-06, 'epoch': 2.21, 'throughput': 1861.74}\n",
      "{'loss': 1.7535, 'grad_norm': 9.0625, 'learning_rate': 8.821578602729242e-06, 'epoch': 2.21, 'num_input_tokens_seen': 318824}\n",
      " 23%|█████████▍                               | 150/650 [02:57<10:05,  1.21s/it]01/02/2025 23:28:29 - INFO - llamafactory.train.callbacks - {'loss': 1.8492, 'learning_rate': 8.7426e-06, 'epoch': 2.29, 'throughput': 1861.46}\n",
      "{'loss': 1.8492, 'grad_norm': 10.0625, 'learning_rate': 8.742553740855507e-06, 'epoch': 2.29, 'num_input_tokens_seen': 330168}\n",
      " 24%|█████████▊                               | 155/650 [03:03<09:59,  1.21s/it]01/02/2025 23:28:35 - INFO - llamafactory.train.callbacks - {'loss': 1.8374, 'learning_rate': 8.6613e-06, 'epoch': 2.37, 'throughput': 1861.99}\n",
      "{'loss': 1.8374, 'grad_norm': 9.9375, 'learning_rate': 8.661343332988869e-06, 'epoch': 2.37, 'num_input_tokens_seen': 341080}\n",
      " 25%|██████████                               | 160/650 [03:08<09:45,  1.19s/it]01/02/2025 23:28:41 - INFO - llamafactory.train.callbacks - {'loss': 1.6842, 'learning_rate': 8.5780e-06, 'epoch': 2.44, 'throughput': 1859.75}\n",
      "{'loss': 1.6842, 'grad_norm': 10.75, 'learning_rate': 8.577994803720605e-06, 'epoch': 2.44, 'num_input_tokens_seen': 351624}\n",
      " 25%|██████████▍                              | 165/650 [03:14<09:14,  1.14s/it]01/02/2025 23:28:46 - INFO - llamafactory.train.callbacks - {'loss': 1.7264, 'learning_rate': 8.4926e-06, 'epoch': 2.52, 'throughput': 1862.2}\n",
      "{'loss': 1.7264, 'grad_norm': 10.5, 'learning_rate': 8.492556826244687e-06, 'epoch': 2.52, 'num_input_tokens_seen': 362616}\n",
      " 26%|██████████▋                              | 170/650 [03:20<10:05,  1.26s/it]01/02/2025 23:28:52 - INFO - llamafactory.train.callbacks - {'loss': 1.8117, 'learning_rate': 8.4051e-06, 'epoch': 2.60, 'throughput': 1862.15}\n",
      "{'loss': 1.8117, 'grad_norm': 11.125, 'learning_rate': 8.405079293933986e-06, 'epoch': 2.6, 'num_input_tokens_seen': 374392}\n",
      " 27%|███████████                              | 175/650 [03:26<09:25,  1.19s/it]01/02/2025 23:28:58 - INFO - llamafactory.train.callbacks - {'loss': 1.7993, 'learning_rate': 8.3156e-06, 'epoch': 2.67, 'throughput': 1861.59}\n",
      "{'loss': 1.7993, 'grad_norm': 10.4375, 'learning_rate': 8.315613291203977e-06, 'epoch': 2.67, 'num_input_tokens_seen': 384824}\n",
      " 28%|███████████▎                             | 180/650 [03:32<09:29,  1.21s/it]01/02/2025 23:29:04 - INFO - llamafactory.train.callbacks - {'loss': 1.8654, 'learning_rate': 8.2242e-06, 'epoch': 2.75, 'throughput': 1861.61}\n",
      "{'loss': 1.8654, 'grad_norm': 9.5, 'learning_rate': 8.224211063680854e-06, 'epoch': 2.75, 'num_input_tokens_seen': 395896}\n",
      " 28%|███████████▋                             | 185/650 [03:38<09:05,  1.17s/it]01/02/2025 23:29:10 - INFO - llamafactory.train.callbacks - {'loss': 1.7306, 'learning_rate': 8.1309e-06, 'epoch': 2.82, 'throughput': 1860.33}\n",
      "{'loss': 1.7306, 'grad_norm': 11.6875, 'learning_rate': 8.13092598769157e-06, 'epoch': 2.82, 'num_input_tokens_seen': 406296}\n",
      " 29%|███████████▉                             | 190/650 [03:44<09:28,  1.24s/it]01/02/2025 23:29:16 - INFO - llamafactory.train.callbacks - {'loss': 1.7297, 'learning_rate': 8.0358e-06, 'epoch': 2.90, 'throughput': 1860.28}\n",
      "{'loss': 1.7297, 'grad_norm': 10.125, 'learning_rate': 8.035812539093557e-06, 'epoch': 2.9, 'num_input_tokens_seen': 417688}\n",
      " 30%|████████████▎                            | 195/650 [03:50<08:50,  1.17s/it]01/02/2025 23:29:22 - INFO - llamafactory.train.callbacks - {'loss': 1.8216, 'learning_rate': 7.9389e-06, 'epoch': 2.98, 'throughput': 1861.79}\n",
      "{'loss': 1.8216, 'grad_norm': 12.4375, 'learning_rate': 7.938926261462366e-06, 'epoch': 2.98, 'num_input_tokens_seen': 429192}\n",
      " 31%|████████████▌                            | 200/650 [03:56<09:19,  1.24s/it]01/02/2025 23:29:28 - INFO - llamafactory.train.callbacks - {'loss': 1.7202, 'learning_rate': 7.8403e-06, 'epoch': 3.05, 'throughput': 1860.89}\n",
      "{'loss': 1.7202, 'grad_norm': 10.5625, 'learning_rate': 7.84032373365578e-06, 'epoch': 3.05, 'num_input_tokens_seen': 440416}\n",
      " 32%|████████████▉                            | 205/650 [04:02<09:19,  1.26s/it]01/02/2025 23:29:34 - INFO - llamafactory.train.callbacks - {'loss': 1.7911, 'learning_rate': 7.7401e-06, 'epoch': 3.13, 'throughput': 1861.25}\n",
      "{'loss': 1.7911, 'grad_norm': 11.0625, 'learning_rate': 7.740062536773352e-06, 'epoch': 3.13, 'num_input_tokens_seen': 452048}\n",
      " 32%|█████████████▏                           | 210/650 [04:08<09:19,  1.27s/it]01/02/2025 23:29:41 - INFO - llamafactory.train.callbacks - {'loss': 1.6312, 'learning_rate': 7.6382e-06, 'epoch': 3.21, 'throughput': 1859.69}\n",
      "{'loss': 1.6312, 'grad_norm': 11.0, 'learning_rate': 7.638201220530664e-06, 'epoch': 3.21, 'num_input_tokens_seen': 463232}\n",
      " 33%|█████████████▌                           | 215/650 [04:14<08:20,  1.15s/it]01/02/2025 23:29:46 - INFO - llamafactory.train.callbacks - {'loss': 1.6043, 'learning_rate': 7.5348e-06, 'epoch': 3.28, 'throughput': 1859.09}\n",
      "{'loss': 1.6043, 'grad_norm': 13.3125, 'learning_rate': 7.534799269067952e-06, 'epoch': 3.28, 'num_input_tokens_seen': 473200}\n",
      " 34%|█████████████▉                           | 220/650 [04:20<08:47,  1.23s/it]01/02/2025 23:29:52 - INFO - llamafactory.train.callbacks - {'loss': 1.6582, 'learning_rate': 7.4299e-06, 'epoch': 3.36, 'throughput': 1860.68}\n",
      "{'loss': 1.6582, 'grad_norm': 9.1875, 'learning_rate': 7.42991706621303e-06, 'epoch': 3.36, 'num_input_tokens_seen': 484816}\n",
      " 35%|██████████████▏                          | 225/650 [04:26<08:52,  1.25s/it]01/02/2025 23:29:58 - INFO - llamafactory.train.callbacks - {'loss': 1.6221, 'learning_rate': 7.3236e-06, 'epoch': 3.44, 'throughput': 1861.48}\n",
      "{'loss': 1.6221, 'grad_norm': 11.625, 'learning_rate': 7.323615860218844e-06, 'epoch': 3.44, 'num_input_tokens_seen': 496656}\n",
      " 35%|██████████████▌                          | 230/650 [04:32<08:32,  1.22s/it]01/02/2025 23:30:04 - INFO - llamafactory.train.callbacks - {'loss': 1.7239, 'learning_rate': 7.2160e-06, 'epoch': 3.51, 'throughput': 1862.56}\n",
      "{'loss': 1.7239, 'grad_norm': 10.0, 'learning_rate': 7.215957727996208e-06, 'epoch': 3.51, 'num_input_tokens_seen': 508512}\n",
      " 36%|██████████████▊                          | 235/650 [04:38<07:19,  1.06s/it]01/02/2025 23:30:10 - INFO - llamafactory.train.callbacks - {'loss': 1.5428, 'learning_rate': 7.1070e-06, 'epoch': 3.59, 'throughput': 1862.6}\n",
      "{'loss': 1.5428, 'grad_norm': 11.125, 'learning_rate': 7.107005538862647e-06, 'epoch': 3.59, 'num_input_tokens_seen': 518448}\n",
      " 37%|███████████████▏                         | 240/650 [04:44<08:03,  1.18s/it]01/02/2025 23:30:16 - INFO - llamafactory.train.callbacks - {'loss': 1.6731, 'learning_rate': 6.9968e-06, 'epoch': 3.66, 'throughput': 1862.12}\n",
      "{'loss': 1.6731, 'grad_norm': 9.25, 'learning_rate': 6.9968229178284775e-06, 'epoch': 3.66, 'num_input_tokens_seen': 529168}\n",
      " 38%|███████████████▍                         | 245/650 [04:49<07:30,  1.11s/it]01/02/2025 23:30:21 - INFO - llamafactory.train.callbacks - {'loss': 1.6444, 'learning_rate': 6.8855e-06, 'epoch': 3.74, 'throughput': 1862.24}\n",
      "{'loss': 1.6444, 'grad_norm': 13.5, 'learning_rate': 6.885474208441602e-06, 'epoch': 3.74, 'num_input_tokens_seen': 539344}\n",
      " 38%|███████████████▊                         | 250/650 [04:55<07:43,  1.16s/it]01/02/2025 23:30:27 - INFO - llamafactory.train.callbacks - {'loss': 1.6568, 'learning_rate': 6.7730e-06, 'epoch': 3.82, 'throughput': 1861.03}\n",
      "{'loss': 1.6568, 'grad_norm': 13.4375, 'learning_rate': 6.773024435212678e-06, 'epoch': 3.82, 'num_input_tokens_seen': 550080}\n",
      " 39%|████████████████                         | 255/650 [05:01<07:42,  1.17s/it]01/02/2025 23:30:33 - INFO - llamafactory.train.callbacks - {'loss': 1.7894, 'learning_rate': 6.6595e-06, 'epoch': 3.89, 'throughput': 1862.17}\n",
      "{'loss': 1.7894, 'grad_norm': 9.5, 'learning_rate': 6.659539265642643e-06, 'epoch': 3.89, 'num_input_tokens_seen': 561360}\n",
      " 40%|████████████████▍                        | 260/650 [05:07<07:24,  1.14s/it]01/02/2025 23:30:39 - INFO - llamafactory.train.callbacks - {'loss': 1.5771, 'learning_rate': 6.5451e-06, 'epoch': 3.97, 'throughput': 1863.4}\n",
      "{'loss': 1.5771, 'grad_norm': 12.3125, 'learning_rate': 6.545084971874738e-06, 'epoch': 3.97, 'num_input_tokens_seen': 572496}\n",
      " 41%|████████████████▋                        | 265/650 [05:13<07:44,  1.21s/it]01/02/2025 23:30:45 - INFO - llamafactory.train.callbacks - {'loss': 1.5783, 'learning_rate': 6.4297e-06, 'epoch': 4.05, 'throughput': 1861.46}\n",
      "{'loss': 1.5783, 'grad_norm': 13.0625, 'learning_rate': 6.429728391993446e-06, 'epoch': 4.05, 'num_input_tokens_seen': 583112}\n",
      " 42%|█████████████████                        | 270/650 [05:19<07:47,  1.23s/it]01/02/2025 23:30:51 - INFO - llamafactory.train.callbacks - {'loss': 1.5914, 'learning_rate': 6.3135e-06, 'epoch': 4.12, 'throughput': 1861.62}\n",
      "{'loss': 1.5914, 'grad_norm': 9.75, 'learning_rate': 6.313536890992935e-06, 'epoch': 4.12, 'num_input_tokens_seen': 594424}\n",
      " 42%|█████████████████▎                       | 275/650 [05:25<07:34,  1.21s/it]01/02/2025 23:30:57 - INFO - llamafactory.train.callbacks - {'loss': 1.5019, 'learning_rate': 6.1966e-06, 'epoch': 4.20, 'throughput': 1862.13}\n",
      "{'loss': 1.5019, 'grad_norm': 17.875, 'learning_rate': 6.1965783214377895e-06, 'epoch': 4.2, 'num_input_tokens_seen': 606088}\n",
      " 43%|█████████████████▋                       | 280/650 [05:31<07:37,  1.24s/it]01/02/2025 23:31:03 - INFO - llamafactory.train.callbacks - {'loss': 1.5772, 'learning_rate': 6.0789e-06, 'epoch': 4.27, 'throughput': 1862.65}\n",
      "{'loss': 1.5772, 'grad_norm': 9.6875, 'learning_rate': 6.078920983839032e-06, 'epoch': 4.27, 'num_input_tokens_seen': 617784}\n",
      " 44%|█████████████████▉                       | 285/650 [05:37<06:55,  1.14s/it]01/02/2025 23:31:09 - INFO - llamafactory.train.callbacks - {'loss': 1.6236, 'learning_rate': 5.9606e-06, 'epoch': 4.35, 'throughput': 1862.44}\n",
      "{'loss': 1.6236, 'grad_norm': 9.875, 'learning_rate': 5.9606335867685424e-06, 'epoch': 4.35, 'num_input_tokens_seen': 628136}\n",
      " 45%|██████████████████▎                      | 290/650 [05:43<07:14,  1.21s/it]01/02/2025 23:31:15 - INFO - llamafactory.train.callbacks - {'loss': 1.6419, 'learning_rate': 5.8418e-06, 'epoch': 4.43, 'throughput': 1862.51}\n",
      "{'loss': 1.6419, 'grad_norm': 11.6875, 'learning_rate': 5.841785206735192e-06, 'epoch': 4.43, 'num_input_tokens_seen': 639464}\n",
      " 45%|██████████████████▌                      | 295/650 [05:49<06:40,  1.13s/it]01/02/2025 23:31:21 - INFO - llamafactory.train.callbacks - {'loss': 1.5124, 'learning_rate': 5.7224e-06, 'epoch': 4.50, 'throughput': 1861.53}\n",
      "{'loss': 1.5124, 'grad_norm': 12.375, 'learning_rate': 5.722445247846107e-06, 'epoch': 4.5, 'num_input_tokens_seen': 650056}\n",
      " 46%|██████████████████▉                      | 300/650 [05:55<07:32,  1.29s/it]01/02/2025 23:31:27 - INFO - llamafactory.train.callbacks - {'loss': 1.5932, 'learning_rate': 5.6027e-06, 'epoch': 4.58, 'throughput': 1861.78}\n",
      "{'loss': 1.5932, 'grad_norm': 9.6875, 'learning_rate': 5.6026834012766155e-06, 'epoch': 4.58, 'num_input_tokens_seen': 662152}\n",
      " 47%|███████████████████▏                     | 305/650 [06:01<06:40,  1.16s/it]01/02/2025 23:31:33 - INFO - llamafactory.train.callbacks - {'loss': 1.6667, 'learning_rate': 5.4826e-06, 'epoch': 4.66, 'throughput': 1862.04}\n",
      "{'loss': 1.6667, 'grad_norm': 14.3125, 'learning_rate': 5.482569604572577e-06, 'epoch': 4.66, 'num_input_tokens_seen': 673176}\n",
      " 48%|███████████████████▌                     | 310/650 [06:07<06:38,  1.17s/it]01/02/2025 23:31:39 - INFO - llamafactory.train.callbacks - {'loss': 1.5128, 'learning_rate': 5.3622e-06, 'epoch': 4.73, 'throughput': 1861.69}\n",
      "{'loss': 1.5128, 'grad_norm': 11.3125, 'learning_rate': 5.362174000808813e-06, 'epoch': 4.73, 'num_input_tokens_seen': 684168}\n",
      " 48%|███████████████████▊                     | 315/650 [06:13<06:31,  1.17s/it]01/02/2025 23:31:45 - INFO - llamafactory.train.callbacks - {'loss': 1.5879, 'learning_rate': 5.2416e-06, 'epoch': 4.81, 'throughput': 1862.23}\n",
      "{'loss': 1.5879, 'grad_norm': 11.75, 'learning_rate': 5.241566897627536e-06, 'epoch': 4.81, 'num_input_tokens_seen': 694984}\n",
      " 49%|████████████████████▏                    | 320/650 [06:18<06:02,  1.10s/it]01/02/2025 23:31:50 - INFO - llamafactory.train.callbacks - {'loss': 1.5063, 'learning_rate': 5.1208e-06, 'epoch': 4.89, 'throughput': 1863.08}\n",
      "{'loss': 1.5063, 'grad_norm': 11.8125, 'learning_rate': 5.120818726180662e-06, 'epoch': 4.89, 'num_input_tokens_seen': 705848}\n",
      " 50%|████████████████████▌                    | 325/650 [06:24<06:30,  1.20s/it]01/02/2025 23:31:56 - INFO - llamafactory.train.callbacks - {'loss': 1.5002, 'learning_rate': 5.0000e-06, 'epoch': 4.96, 'throughput': 1863.13}\n",
      "{'loss': 1.5002, 'grad_norm': 11.125, 'learning_rate': 5e-06, 'epoch': 4.96, 'num_input_tokens_seen': 717352}\n",
      " 51%|████████████████████▊                    | 330/650 [06:30<06:00,  1.13s/it]01/02/2025 23:32:02 - INFO - llamafactory.train.callbacks - {'loss': 1.6269, 'learning_rate': 4.8792e-06, 'epoch': 5.04, 'throughput': 1863.51}\n",
      "{'loss': 1.6269, 'grad_norm': 10.75, 'learning_rate': 4.87918127381934e-06, 'epoch': 5.04, 'num_input_tokens_seen': 727624}\n",
      " 52%|█████████████████████▏                   | 335/650 [06:35<05:49,  1.11s/it]01/02/2025 23:32:08 - INFO - llamafactory.train.callbacks - {'loss': 1.6347, 'learning_rate': 4.7584e-06, 'epoch': 5.11, 'throughput': 1864.6}\n",
      "{'loss': 1.6347, 'grad_norm': 11.1875, 'learning_rate': 4.758433102372466e-06, 'epoch': 5.11, 'num_input_tokens_seen': 738616}\n",
      " 52%|█████████████████████▍                   | 340/650 [06:41<06:14,  1.21s/it]01/02/2025 23:32:14 - INFO - llamafactory.train.callbacks - {'loss': 1.4099, 'learning_rate': 4.6378e-06, 'epoch': 5.19, 'throughput': 1863.95}\n",
      "{'loss': 1.4099, 'grad_norm': 10.375, 'learning_rate': 4.637825999191189e-06, 'epoch': 5.19, 'num_input_tokens_seen': 749464}\n",
      " 53%|█████████████████████▊                   | 345/650 [06:47<06:16,  1.23s/it]01/02/2025 23:32:20 - INFO - llamafactory.train.callbacks - {'loss': 1.3839, 'learning_rate': 4.5174e-06, 'epoch': 5.27, 'throughput': 1863.41}\n",
      "{'loss': 1.3839, 'grad_norm': 11.6875, 'learning_rate': 4.517430395427424e-06, 'epoch': 5.27, 'num_input_tokens_seen': 760488}\n",
      " 54%|██████████████████████                   | 350/650 [06:53<05:51,  1.17s/it]01/02/2025 23:32:25 - INFO - llamafactory.train.callbacks - {'loss': 1.5822, 'learning_rate': 4.3973e-06, 'epoch': 5.34, 'throughput': 1863.8}\n",
      "{'loss': 1.5822, 'grad_norm': 9.625, 'learning_rate': 4.397316598723385e-06, 'epoch': 5.34, 'num_input_tokens_seen': 771656}\n",
      " 55%|██████████████████████▍                  | 355/650 [06:59<05:38,  1.15s/it]01/02/2025 23:32:31 - INFO - llamafactory.train.callbacks - {'loss': 1.4999, 'learning_rate': 4.2776e-06, 'epoch': 5.42, 'throughput': 1863.76}\n",
      "{'loss': 1.4999, 'grad_norm': 11.1875, 'learning_rate': 4.277554752153895e-06, 'epoch': 5.42, 'num_input_tokens_seen': 782568}\n",
      " 55%|██████████████████████▋                  | 360/650 [07:05<05:36,  1.16s/it]01/02/2025 23:32:37 - INFO - llamafactory.train.callbacks - {'loss': 1.5456, 'learning_rate': 4.1582e-06, 'epoch': 5.50, 'throughput': 1863.57}\n",
      "{'loss': 1.5456, 'grad_norm': 11.875, 'learning_rate': 4.158214793264808e-06, 'epoch': 5.5, 'num_input_tokens_seen': 793512}\n",
      " 56%|███████████████████████                  | 365/650 [07:11<05:35,  1.18s/it]01/02/2025 23:32:43 - INFO - llamafactory.train.callbacks - {'loss': 1.4232, 'learning_rate': 4.0394e-06, 'epoch': 5.57, 'throughput': 1863.52}\n",
      "{'loss': 1.4232, 'grad_norm': 10.125, 'learning_rate': 4.039366413231458e-06, 'epoch': 5.57, 'num_input_tokens_seen': 804232}\n",
      " 57%|███████████████████████▎                 | 370/650 [07:17<05:26,  1.16s/it]01/02/2025 23:32:49 - INFO - llamafactory.train.callbacks - {'loss': 1.4325, 'learning_rate': 3.9211e-06, 'epoch': 5.65, 'throughput': 1863.34}\n",
      "{'loss': 1.4325, 'grad_norm': 10.6875, 'learning_rate': 3.92107901616097e-06, 'epoch': 5.65, 'num_input_tokens_seen': 815032}\n",
      " 58%|███████████████████████▋                 | 375/650 [07:23<05:33,  1.21s/it]01/02/2025 23:32:55 - INFO - llamafactory.train.callbacks - {'loss': 1.4616, 'learning_rate': 3.8034e-06, 'epoch': 5.73, 'throughput': 1863.73}\n",
      "{'loss': 1.4616, 'grad_norm': 10.5, 'learning_rate': 3.803421678562213e-06, 'epoch': 5.73, 'num_input_tokens_seen': 826424}\n",
      " 58%|███████████████████████▉                 | 380/650 [07:29<05:32,  1.23s/it]01/02/2025 23:33:01 - INFO - llamafactory.train.callbacks - {'loss': 1.6915, 'learning_rate': 3.6865e-06, 'epoch': 5.80, 'throughput': 1864.77}\n",
      "{'loss': 1.6915, 'grad_norm': 11.5625, 'learning_rate': 3.6864631090070656e-06, 'epoch': 5.8, 'num_input_tokens_seen': 839032}\n",
      " 59%|████████████████████████▎                | 385/650 [07:35<04:58,  1.13s/it]01/02/2025 23:33:07 - INFO - llamafactory.train.callbacks - {'loss': 1.4245, 'learning_rate': 3.5703e-06, 'epoch': 5.88, 'throughput': 1863.58}\n",
      "{'loss': 1.4245, 'grad_norm': 16.625, 'learning_rate': 3.5702716080065546e-06, 'epoch': 5.88, 'num_input_tokens_seen': 849032}\n",
      " 60%|████████████████████████▌                | 390/650 [07:41<05:14,  1.21s/it]01/02/2025 23:33:13 - INFO - llamafactory.train.callbacks - {'loss': 1.4917, 'learning_rate': 3.4549e-06, 'epoch': 5.95, 'throughput': 1864.19}\n",
      "{'loss': 1.4917, 'grad_norm': 10.5, 'learning_rate': 3.4549150281252635e-06, 'epoch': 5.95, 'num_input_tokens_seen': 860808}\n",
      " 61%|████████████████████████▉                | 395/650 [07:47<04:59,  1.17s/it]01/02/2025 23:33:19 - INFO - llamafactory.train.callbacks - {'loss': 1.5078, 'learning_rate': 3.3405e-06, 'epoch': 6.03, 'throughput': 1864.64}\n",
      "{'loss': 1.5078, 'grad_norm': 10.25, 'learning_rate': 3.340460734357359e-06, 'epoch': 6.03, 'num_input_tokens_seen': 871888}\n",
      " 62%|█████████████████████████▏               | 400/650 [07:52<04:18,  1.03s/it]01/02/2025 23:33:24 - INFO - llamafactory.train.callbacks - {'loss': 1.3138, 'learning_rate': 3.2270e-06, 'epoch': 6.11, 'throughput': 1864.28}\n",
      "{'loss': 1.3138, 'grad_norm': 13.5625, 'learning_rate': 3.226975564787322e-06, 'epoch': 6.11, 'num_input_tokens_seen': 881312}\n",
      " 62%|█████████████████████████▌               | 405/650 [07:58<04:44,  1.16s/it]01/02/2025 23:33:30 - INFO - llamafactory.train.callbacks - {'loss': 1.5186, 'learning_rate': 3.1145e-06, 'epoch': 6.18, 'throughput': 1864.82}\n",
      "{'loss': 1.5186, 'grad_norm': 10.75, 'learning_rate': 3.114525791558398e-06, 'epoch': 6.18, 'num_input_tokens_seen': 892096}\n",
      " 63%|█████████████████████████▊               | 410/650 [08:04<04:48,  1.20s/it]01/02/2025 23:33:36 - INFO - llamafactory.train.callbacks - {'loss': 1.3969, 'learning_rate': 3.0032e-06, 'epoch': 6.26, 'throughput': 1864.66}\n",
      "{'loss': 1.3969, 'grad_norm': 10.4375, 'learning_rate': 3.0031770821715233e-06, 'epoch': 6.26, 'num_input_tokens_seen': 903376}\n",
      " 64%|██████████████████████████▏              | 415/650 [08:10<04:33,  1.16s/it]01/02/2025 23:33:42 - INFO - llamafactory.train.callbacks - {'loss': 1.4370, 'learning_rate': 2.8930e-06, 'epoch': 6.34, 'throughput': 1864.6}\n",
      "{'loss': 1.437, 'grad_norm': 11.375, 'learning_rate': 2.8929944611373555e-06, 'epoch': 6.34, 'num_input_tokens_seen': 914560}\n",
      " 65%|██████████████████████████▍              | 420/650 [08:16<04:51,  1.27s/it]01/02/2025 23:33:48 - INFO - llamafactory.train.callbacks - {'loss': 1.6432, 'learning_rate': 2.7840e-06, 'epoch': 6.41, 'throughput': 1864.41}\n",
      "{'loss': 1.6432, 'grad_norm': 12.1875, 'learning_rate': 2.7840422720037943e-06, 'epoch': 6.41, 'num_input_tokens_seen': 926496}\n",
      " 65%|██████████████████████████▊              | 425/650 [08:22<04:36,  1.23s/it]01/02/2025 23:33:55 - INFO - llamafactory.train.callbacks - {'loss': 1.5579, 'learning_rate': 2.6764e-06, 'epoch': 6.49, 'throughput': 1864.19}\n",
      "{'loss': 1.5579, 'grad_norm': 11.0, 'learning_rate': 2.6763841397811576e-06, 'epoch': 6.49, 'num_input_tokens_seen': 937872}\n",
      " 66%|███████████████████████████              | 430/650 [08:28<04:33,  1.24s/it]01/02/2025 23:34:01 - INFO - llamafactory.train.callbacks - {'loss': 1.4637, 'learning_rate': 2.5701e-06, 'epoch': 6.56, 'throughput': 1864.52}\n",
      "{'loss': 1.4637, 'grad_norm': 10.125, 'learning_rate': 2.57008293378697e-06, 'epoch': 6.56, 'num_input_tokens_seen': 949232}\n",
      " 67%|███████████████████████████▍             | 435/650 [08:35<04:26,  1.24s/it]01/02/2025 23:34:07 - INFO - llamafactory.train.callbacks - {'loss': 1.6154, 'learning_rate': 2.4652e-06, 'epoch': 6.64, 'throughput': 1864.65}\n",
      "{'loss': 1.6154, 'grad_norm': 9.875, 'learning_rate': 2.4652007309320497e-06, 'epoch': 6.64, 'num_input_tokens_seen': 960784}\n",
      " 68%|███████████████████████████▊             | 440/650 [08:41<04:17,  1.23s/it]01/02/2025 23:34:13 - INFO - llamafactory.train.callbacks - {'loss': 1.4695, 'learning_rate': 2.3618e-06, 'epoch': 6.72, 'throughput': 1864.09}\n",
      "{'loss': 1.4695, 'grad_norm': 10.6875, 'learning_rate': 2.3617987794693358e-06, 'epoch': 6.72, 'num_input_tokens_seen': 971904}\n",
      " 68%|████████████████████████████             | 445/650 [08:47<04:16,  1.25s/it]01/02/2025 23:34:19 - INFO - llamafactory.train.callbacks - {'loss': 1.4661, 'learning_rate': 2.2599e-06, 'epoch': 6.79, 'throughput': 1863.92}\n",
      "{'loss': 1.4661, 'grad_norm': 12.4375, 'learning_rate': 2.2599374632266514e-06, 'epoch': 6.79, 'num_input_tokens_seen': 983168}\n",
      " 69%|████████████████████████████▍            | 450/650 [08:53<03:57,  1.19s/it]01/02/2025 23:34:25 - INFO - llamafactory.train.callbacks - {'loss': 1.5463, 'learning_rate': 2.1597e-06, 'epoch': 6.87, 'throughput': 1863.99}\n",
      "{'loss': 1.5463, 'grad_norm': 12.5625, 'learning_rate': 2.159676266344222e-06, 'epoch': 6.87, 'num_input_tokens_seen': 994240}\n",
      " 70%|████████████████████████████▋            | 455/650 [08:58<03:49,  1.17s/it]01/02/2025 23:34:31 - INFO - llamafactory.train.callbacks - {'loss': 1.3950, 'learning_rate': 2.0611e-06, 'epoch': 6.95, 'throughput': 1863.91}\n",
      "{'loss': 1.395, 'grad_norm': 9.4375, 'learning_rate': 2.061073738537635e-06, 'epoch': 6.95, 'num_input_tokens_seen': 1004832}\n",
      " 71%|█████████████████████████████            | 460/650 [09:04<03:39,  1.15s/it]01/02/2025 23:34:36 - INFO - llamafactory.train.callbacks - {'loss': 1.4800, 'learning_rate': 1.9642e-06, 'epoch': 7.02, 'throughput': 1863.51}\n",
      "{'loss': 1.48, 'grad_norm': 11.1875, 'learning_rate': 1.9641874609064443e-06, 'epoch': 7.02, 'num_input_tokens_seen': 1015248}\n",
      " 72%|█████████████████████████████▎           | 465/650 [09:10<03:36,  1.17s/it]01/02/2025 23:34:42 - INFO - llamafactory.train.callbacks - {'loss': 1.3295, 'learning_rate': 1.8691e-06, 'epoch': 7.10, 'throughput': 1864.3}\n",
      "{'loss': 1.3295, 'grad_norm': 9.5, 'learning_rate': 1.8690740123084316e-06, 'epoch': 7.1, 'num_input_tokens_seen': 1026384}\n",
      " 72%|█████████████████████████████▋           | 470/650 [09:16<03:26,  1.15s/it]01/02/2025 23:34:48 - INFO - llamafactory.train.callbacks - {'loss': 1.3877, 'learning_rate': 1.7758e-06, 'epoch': 7.18, 'throughput': 1864.11}\n",
      "{'loss': 1.3877, 'grad_norm': 11.5625, 'learning_rate': 1.7757889363191484e-06, 'epoch': 7.18, 'num_input_tokens_seen': 1036880}\n",
      " 73%|█████████████████████████████▉           | 475/650 [09:21<03:27,  1.19s/it]01/02/2025 23:34:53 - INFO - llamafactory.train.callbacks - {'loss': 1.4590, 'learning_rate': 1.6844e-06, 'epoch': 7.25, 'throughput': 1864.03}\n",
      "{'loss': 1.459, 'grad_norm': 10.4375, 'learning_rate': 1.6843867087960252e-06, 'epoch': 7.25, 'num_input_tokens_seen': 1047616}\n",
      " 74%|██████████████████████████████▎          | 480/650 [09:27<03:19,  1.17s/it]01/02/2025 23:34:59 - INFO - llamafactory.train.callbacks - {'loss': 1.4440, 'learning_rate': 1.5949e-06, 'epoch': 7.33, 'throughput': 1863.55}\n",
      "{'loss': 1.444, 'grad_norm': 10.3125, 'learning_rate': 1.5949207060660138e-06, 'epoch': 7.33, 'num_input_tokens_seen': 1058448}\n",
      " 75%|██████████████████████████████▌          | 485/650 [09:33<03:26,  1.25s/it]01/02/2025 23:35:06 - INFO - llamafactory.train.callbacks - {'loss': 1.4490, 'learning_rate': 1.5074e-06, 'epoch': 7.40, 'throughput': 1863.55}\n",
      "{'loss': 1.449, 'grad_norm': 8.875, 'learning_rate': 1.5074431737553158e-06, 'epoch': 7.4, 'num_input_tokens_seen': 1069888}\n",
      " 75%|██████████████████████████████▉          | 490/650 [09:39<03:18,  1.24s/it]01/02/2025 23:35:12 - INFO - llamafactory.train.callbacks - {'loss': 1.3878, 'learning_rate': 1.4220e-06, 'epoch': 7.48, 'throughput': 1862.45}\n",
      "{'loss': 1.3878, 'grad_norm': 10.125, 'learning_rate': 1.4220051962793952e-06, 'epoch': 7.48, 'num_input_tokens_seen': 1080384}\n",
      " 76%|███████████████████████████████▏         | 495/650 [09:45<02:59,  1.16s/it]01/02/2025 23:35:17 - INFO - llamafactory.train.callbacks - {'loss': 1.5812, 'learning_rate': 1.3387e-06, 'epoch': 7.56, 'throughput': 1862.34}\n",
      "{'loss': 1.5812, 'grad_norm': 12.6875, 'learning_rate': 1.3386566670111339e-06, 'epoch': 7.56, 'num_input_tokens_seen': 1091264}\n",
      " 77%|███████████████████████████████▌         | 500/650 [09:51<02:55,  1.17s/it]01/02/2025 23:35:23 - INFO - llamafactory.train.callbacks - {'loss': 1.4572, 'learning_rate': 1.2574e-06, 'epoch': 7.63, 'throughput': 1862.1}\n",
      "{'loss': 1.4572, 'grad_norm': 11.875, 'learning_rate': 1.257446259144494e-06, 'epoch': 7.63, 'num_input_tokens_seen': 1102064}\n",
      " 78%|███████████████████████████████▊         | 505/650 [09:58<03:01,  1.25s/it]01/02/2025 23:35:30 - INFO - llamafactory.train.callbacks - {'loss': 1.5626, 'learning_rate': 1.1784e-06, 'epoch': 7.71, 'throughput': 1862.62}\n",
      "{'loss': 1.5626, 'grad_norm': 9.5625, 'learning_rate': 1.1784213972707581e-06, 'epoch': 7.71, 'num_input_tokens_seen': 1114480}\n",
      " 78%|████████████████████████████████▏        | 510/650 [10:04<02:39,  1.14s/it]01/02/2025 23:35:36 - INFO - llamafactory.train.callbacks - {'loss': 1.4383, 'learning_rate': 1.1016e-06, 'epoch': 7.79, 'throughput': 1862.79}\n",
      "{'loss': 1.4383, 'grad_norm': 10.5625, 'learning_rate': 1.1016282296838887e-06, 'epoch': 7.79, 'num_input_tokens_seen': 1125456}\n",
      " 79%|████████████████████████████████▍        | 515/650 [10:09<02:27,  1.09s/it]01/02/2025 23:35:41 - INFO - llamafactory.train.callbacks - {'loss': 1.5645, 'learning_rate': 1.0271e-06, 'epoch': 7.86, 'throughput': 1863.16}\n",
      "{'loss': 1.5645, 'grad_norm': 12.3125, 'learning_rate': 1.0271116014312293e-06, 'epoch': 7.86, 'num_input_tokens_seen': 1136176}\n",
      " 80%|████████████████████████████████▊        | 520/650 [10:15<02:35,  1.20s/it]01/02/2025 23:35:47 - INFO - llamafactory.train.callbacks - {'loss': 1.5217, 'learning_rate': 9.5492e-07, 'epoch': 7.94, 'throughput': 1863.26}\n",
      "{'loss': 1.5217, 'grad_norm': 9.4375, 'learning_rate': 9.549150281252633e-07, 'epoch': 7.94, 'num_input_tokens_seen': 1147120}\n",
      " 81%|█████████████████████████████████        | 525/650 [10:21<02:23,  1.15s/it]01/02/2025 23:35:53 - INFO - llamafactory.train.callbacks - {'loss': 1.6138, 'learning_rate': 8.8508e-07, 'epoch': 8.02, 'throughput': 1863.43}\n",
      "{'loss': 1.6138, 'grad_norm': 11.25, 'learning_rate': 8.850806705317183e-07, 'epoch': 8.02, 'num_input_tokens_seen': 1158208}\n",
      " 82%|█████████████████████████████████▍       | 530/650 [10:27<02:25,  1.21s/it]01/02/2025 23:35:59 - INFO - llamafactory.train.callbacks - {'loss': 1.5281, 'learning_rate': 8.1765e-07, 'epoch': 8.09, 'throughput': 1863.63}\n",
      "{'loss': 1.5281, 'grad_norm': 9.125, 'learning_rate': 8.176493099488664e-07, 'epoch': 8.09, 'num_input_tokens_seen': 1169712}\n",
      " 82%|█████████████████████████████████▋       | 535/650 [10:33<02:13,  1.16s/it]01/02/2025 23:36:05 - INFO - llamafactory.train.callbacks - {'loss': 1.5693, 'learning_rate': 7.5266e-07, 'epoch': 8.17, 'throughput': 1863.61}\n",
      "{'loss': 1.5693, 'grad_norm': 9.375, 'learning_rate': 7.526603243923958e-07, 'epoch': 8.17, 'num_input_tokens_seen': 1180240}\n",
      " 83%|██████████████████████████████████       | 540/650 [10:39<02:14,  1.22s/it]01/02/2025 23:36:11 - INFO - llamafactory.train.callbacks - {'loss': 1.4584, 'learning_rate': 6.9015e-07, 'epoch': 8.24, 'throughput': 1863.88}\n",
      "{'loss': 1.4584, 'grad_norm': 10.5, 'learning_rate': 6.901516655997536e-07, 'epoch': 8.24, 'num_input_tokens_seen': 1191904}\n",
      " 84%|██████████████████████████████████▍      | 545/650 [10:44<02:00,  1.15s/it]01/02/2025 23:36:17 - INFO - llamafactory.train.callbacks - {'loss': 1.4607, 'learning_rate': 6.3016e-07, 'epoch': 8.32, 'throughput': 1863.92}\n",
      "{'loss': 1.4607, 'grad_norm': 12.4375, 'learning_rate': 6.301598368674106e-07, 'epoch': 8.32, 'num_input_tokens_seen': 1202464}\n",
      " 85%|██████████████████████████████████▋      | 550/650 [10:51<01:59,  1.19s/it]01/02/2025 23:36:23 - INFO - llamafactory.train.callbacks - {'loss': 1.4450, 'learning_rate': 5.7272e-07, 'epoch': 8.40, 'throughput': 1864.28}\n",
      "{'loss': 1.445, 'grad_norm': 9.1875, 'learning_rate': 5.727198717339511e-07, 'epoch': 8.4, 'num_input_tokens_seen': 1213920}\n",
      " 85%|███████████████████████████████████      | 555/650 [10:57<01:53,  1.20s/it]01/02/2025 23:36:29 - INFO - llamafactory.train.callbacks - {'loss': 1.5169, 'learning_rate': 5.1787e-07, 'epoch': 8.47, 'throughput': 1864.04}\n",
      "{'loss': 1.5169, 'grad_norm': 10.375, 'learning_rate': 5.178653135214811e-07, 'epoch': 8.47, 'num_input_tokens_seen': 1225328}\n",
      " 86%|███████████████████████████████████▎     | 560/650 [11:02<01:43,  1.15s/it]01/02/2025 23:36:35 - INFO - llamafactory.train.callbacks - {'loss': 1.6687, 'learning_rate': 4.6563e-07, 'epoch': 8.55, 'throughput': 1864.06}\n",
      "{'loss': 1.6687, 'grad_norm': 10.0625, 'learning_rate': 4.6562819574727304e-07, 'epoch': 8.55, 'num_input_tokens_seen': 1236112}\n",
      " 87%|███████████████████████████████████▋     | 565/650 [11:09<01:43,  1.21s/it]01/02/2025 23:36:41 - INFO - llamafactory.train.callbacks - {'loss': 1.3735, 'learning_rate': 4.1604e-07, 'epoch': 8.63, 'throughput': 1863.51}\n",
      "{'loss': 1.3735, 'grad_norm': 10.625, 'learning_rate': 4.1603902341708804e-07, 'epoch': 8.63, 'num_input_tokens_seen': 1247072}\n",
      " 88%|███████████████████████████████████▉     | 570/650 [11:14<01:30,  1.14s/it]01/02/2025 23:36:46 - INFO - llamafactory.train.callbacks - {'loss': 1.4146, 'learning_rate': 3.6913e-07, 'epoch': 8.70, 'throughput': 1863.42}\n",
      "{'loss': 1.4146, 'grad_norm': 11.5, 'learning_rate': 3.691267552111183e-07, 'epoch': 8.7, 'num_input_tokens_seen': 1257456}\n",
      " 88%|████████████████████████████████████▎    | 575/650 [11:20<01:26,  1.15s/it]01/02/2025 23:36:52 - INFO - llamafactory.train.callbacks - {'loss': 1.3573, 'learning_rate': 3.2492e-07, 'epoch': 8.78, 'throughput': 1863.35}\n",
      "{'loss': 1.3573, 'grad_norm': 9.5625, 'learning_rate': 3.2491878657292643e-07, 'epoch': 8.78, 'num_input_tokens_seen': 1268144}\n",
      " 89%|████████████████████████████████████▌    | 580/650 [11:26<01:31,  1.31s/it]01/02/2025 23:36:58 - INFO - llamafactory.train.callbacks - {'loss': 1.5000, 'learning_rate': 2.8344e-07, 'epoch': 8.85, 'throughput': 1862.98}\n",
      "{'loss': 1.5, 'grad_norm': 10.4375, 'learning_rate': 2.834409337112842e-07, 'epoch': 8.85, 'num_input_tokens_seen': 1279488}\n",
      " 90%|████████████████████████████████████▉    | 585/650 [11:32<01:21,  1.25s/it]01/02/2025 23:37:05 - INFO - llamafactory.train.callbacks - {'loss': 1.4033, 'learning_rate': 2.4472e-07, 'epoch': 8.93, 'throughput': 1862.88}\n",
      "{'loss': 1.4033, 'grad_norm': 10.6875, 'learning_rate': 2.447174185242324e-07, 'epoch': 8.93, 'num_input_tokens_seen': 1291152}\n",
      " 91%|█████████████████████████████████████▏   | 590/650 [11:38<01:01,  1.03s/it]01/02/2025 23:37:10 - INFO - llamafactory.train.callbacks - {'loss': 1.2989, 'learning_rate': 2.0877e-07, 'epoch': 9.01, 'throughput': 1862.21}\n",
      "{'loss': 1.2989, 'grad_norm': 21.375, 'learning_rate': 2.0877085445416889e-07, 'epoch': 9.01, 'num_input_tokens_seen': 1300288}\n",
      " 92%|█████████████████████████████████████▌   | 595/650 [11:43<00:58,  1.07s/it]01/02/2025 23:37:15 - INFO - llamafactory.train.callbacks - {'loss': 1.4220, 'learning_rate': 1.7562e-07, 'epoch': 9.08, 'throughput': 1862.09}\n",
      "{'loss': 1.422, 'grad_norm': 10.875, 'learning_rate': 1.7562223328224327e-07, 'epoch': 9.08, 'num_input_tokens_seen': 1310400}\n",
      " 92%|█████████████████████████████████████▊   | 600/650 [11:49<00:56,  1.13s/it]01/02/2025 23:37:21 - INFO - llamafactory.train.callbacks - {'loss': 1.4408, 'learning_rate': 1.4529e-07, 'epoch': 9.16, 'throughput': 1861.66}\n",
      "{'loss': 1.4408, 'grad_norm': 11.5625, 'learning_rate': 1.4529091286973994e-07, 'epoch': 9.16, 'num_input_tokens_seen': 1320832}\n",
      " 93%|██████████████████████████████████████▏  | 605/650 [11:55<00:53,  1.19s/it]01/02/2025 23:37:27 - INFO - llamafactory.train.callbacks - {'loss': 1.4024, 'learning_rate': 1.1779e-07, 'epoch': 9.24, 'throughput': 1861.79}\n",
      "{'loss': 1.4024, 'grad_norm': 10.9375, 'learning_rate': 1.1779460585363945e-07, 'epoch': 9.24, 'num_input_tokens_seen': 1332176}\n",
      " 94%|██████████████████████████████████████▍  | 610/650 [12:01<00:46,  1.15s/it]01/02/2025 23:37:33 - INFO - llamafactory.train.callbacks - {'loss': 1.3908, 'learning_rate': 9.3149e-08, 'epoch': 9.31, 'throughput': 1861.83}\n",
      "{'loss': 1.3908, 'grad_norm': 13.0625, 'learning_rate': 9.314936930293283e-08, 'epoch': 9.31, 'num_input_tokens_seen': 1342944}\n",
      " 95%|██████████████████████████████████████▊  | 615/650 [12:07<00:40,  1.17s/it]01/02/2025 23:37:39 - INFO - llamafactory.train.callbacks - {'loss': 1.5050, 'learning_rate': 7.1370e-08, 'epoch': 9.39, 'throughput': 1862.09}\n",
      "{'loss': 1.505, 'grad_norm': 10.625, 'learning_rate': 7.136959534174592e-08, 'epoch': 9.39, 'num_input_tokens_seen': 1354160}\n",
      " 95%|███████████████████████████████████████  | 620/650 [12:13<00:36,  1.23s/it]01/02/2025 23:37:45 - INFO - llamafactory.train.callbacks - {'loss': 1.5478, 'learning_rate': 5.2468e-08, 'epoch': 9.47, 'throughput': 1861.85}\n",
      "{'loss': 1.5478, 'grad_norm': 11.6875, 'learning_rate': 5.246800274474439e-08, 'epoch': 9.47, 'num_input_tokens_seen': 1365936}\n",
      " 96%|███████████████████████████████████████▍ | 625/650 [12:19<00:30,  1.21s/it]01/02/2025 23:37:51 - INFO - llamafactory.train.callbacks - {'loss': 1.5218, 'learning_rate': 3.6456e-08, 'epoch': 9.54, 'throughput': 1862.09}\n",
      "{'loss': 1.5218, 'grad_norm': 11.0625, 'learning_rate': 3.645562950973014e-08, 'epoch': 9.54, 'num_input_tokens_seen': 1377296}\n",
      " 97%|███████████████████████████████████████▋ | 630/650 [12:25<00:23,  1.19s/it]01/02/2025 23:37:57 - INFO - llamafactory.train.callbacks - {'loss': 1.5144, 'learning_rate': 2.3342e-08, 'epoch': 9.62, 'throughput': 1862.37}\n",
      "{'loss': 1.5144, 'grad_norm': 10.625, 'learning_rate': 2.3341826411756863e-08, 'epoch': 9.62, 'num_input_tokens_seen': 1388560}\n",
      " 98%|████████████████████████████████████████ | 635/650 [12:31<00:17,  1.14s/it]01/02/2025 23:38:03 - INFO - llamafactory.train.callbacks - {'loss': 1.4368, 'learning_rate': 1.3134e-08, 'epoch': 9.69, 'throughput': 1862.5}\n",
      "{'loss': 1.4368, 'grad_norm': 11.6875, 'learning_rate': 1.3134251542544774e-08, 'epoch': 9.69, 'num_input_tokens_seen': 1399488}\n",
      " 98%|████████████████████████████████████████▎| 640/650 [12:37<00:12,  1.23s/it]01/02/2025 23:38:09 - INFO - llamafactory.train.callbacks - {'loss': 1.5718, 'learning_rate': 5.8389e-09, 'epoch': 9.77, 'throughput': 1862.87}\n",
      "{'loss': 1.5718, 'grad_norm': 9.125, 'learning_rate': 5.838865838366792e-09, 'epoch': 9.77, 'num_input_tokens_seen': 1411600}\n",
      " 99%|████████████████████████████████████████▋| 645/650 [12:43<00:05,  1.13s/it]01/02/2025 23:38:15 - INFO - llamafactory.train.callbacks - {'loss': 1.3842, 'learning_rate': 1.4599e-09, 'epoch': 9.85, 'throughput': 1862.76}\n",
      "{'loss': 1.3842, 'grad_norm': 10.25, 'learning_rate': 1.4599295990352924e-09, 'epoch': 9.85, 'num_input_tokens_seen': 1422096}\n",
      "100%|█████████████████████████████████████████| 650/650 [12:49<00:00,  1.12s/it]01/02/2025 23:38:21 - INFO - llamafactory.train.callbacks - {'loss': 1.4855, 'learning_rate': 0.0000e+00, 'epoch': 9.92, 'throughput': 1862.56}\n",
      "{'loss': 1.4855, 'grad_norm': 11.0, 'learning_rate': 0.0, 'epoch': 9.92, 'num_input_tokens_seen': 1432816}\n",
      "100%|█████████████████████████████████████████| 650/650 [12:49<00:00,  1.12s/it][INFO|trainer.py:3639] 2025-01-02 23:38:21,216 >> Saving model checkpoint to saves/Qwen2VL-2B-Chat/full/train_qwen_vl/checkpoint-650\n",
      "[INFO|configuration_utils.py:407] 2025-01-02 23:38:21,219 >> Configuration saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/checkpoint-650/config.json\n",
      "[INFO|configuration_utils.py:829] 2025-01-02 23:38:21,220 >> Configuration saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/checkpoint-650/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2025-01-02 23:38:30,212 >> Model weights saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/checkpoint-650/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2597] 2025-01-02 23:38:30,213 >> tokenizer config file saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/checkpoint-650/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2606] 2025-01-02 23:38:30,213 >> Special tokens file saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/checkpoint-650/special_tokens_map.json\n",
      "[INFO|image_processing_base.py:258] 2025-01-02 23:38:59,394 >> Image processor saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/checkpoint-650/preprocessor_config.json\n",
      "[INFO|trainer.py:2442] 2025-01-02 23:38:59,394 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 807.4531, 'train_samples_per_second': 3.232, 'train_steps_per_second': 0.805, 'train_loss': 1.6748976744138278, 'epoch': 9.92, 'num_input_tokens_seen': 1432816}\n",
      "100%|█████████████████████████████████████████| 650/650 [13:27<00:00,  1.24s/it]\n",
      "[INFO|image_processing_base.py:258] 2025-01-02 23:38:59,395 >> Image processor saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/preprocessor_config.json\n",
      "[INFO|trainer.py:3639] 2025-01-02 23:38:59,395 >> Saving model checkpoint to saves/Qwen2VL-2B-Chat/full/train_qwen_vl\n",
      "[INFO|configuration_utils.py:407] 2025-01-02 23:38:59,398 >> Configuration saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/config.json\n",
      "[INFO|configuration_utils.py:829] 2025-01-02 23:38:59,398 >> Configuration saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/generation_config.json\n",
      "[INFO|modeling_utils.py:2795] 2025-01-02 23:39:29,369 >> Model weights saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2597] 2025-01-02 23:39:29,370 >> tokenizer config file saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2606] 2025-01-02 23:39:29,370 >> Special tokens file saved in saves/Qwen2VL-2B-Chat/full/train_qwen_vl/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =     9.9237\n",
      "  num_input_tokens_seen    =    1432816\n",
      "  total_flos               = 15817703GF\n",
      "  train_loss               =     1.6749\n",
      "  train_runtime            = 0:13:27.45\n",
      "  train_samples_per_second =      3.232\n",
      "  train_steps_per_second   =      0.805\n",
      "Figure saved at: saves/Qwen2VL-2B-Chat/full/train_qwen_vl/training_loss.png\n",
      "01/02/2025 23:39:31 - WARNING - llamafactory.extras.ploting - No metric eval_loss to plot.\n",
      "01/02/2025 23:39:31 - WARNING - llamafactory.extras.ploting - No metric eval_accuracy to plot.\n",
      "[INFO|modelcard.py:449] 2025-01-02 23:39:31,116 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:39:46,477 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:39:46,478 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"saves/Qwen2VL-2B-Chat/full/train_qwen_vl\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:46,479 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:46,479 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:46,480 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:46,480 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:46,480 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:46,480 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:39:46,648 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:39:47,215 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:39:47,216 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:429] 2025-01-02 23:39:47,217 >> Image processor Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:47,217 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:47,217 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:47,217 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:47,217 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:47,217 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:39:47,217 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:39:47,383 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|processing_utils.py:722] 2025-01-02 23:39:47,608 >> Processor Qwen2VLProcessor:\n",
      "- image_processor: Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "- tokenizer: Qwen2TokenizerFast(name_or_path='saves/Qwen2VL-2B-Chat/full/train_qwen_vl', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "\n",
      "{\n",
      "  \"chat_template\": null,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\"\n",
      "}\n",
      "\n",
      "01/02/2025 23:39:47 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:39:47,631 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:39:47,632 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"saves/Qwen2VL-2B-Chat/full/train_qwen_vl\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "01/02/2025 23:39:47 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n",
      "[INFO|modeling_utils.py:3671] 2025-01-02 23:39:47,640 >> loading weights file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/model.safetensors\n",
      "[INFO|modeling_utils.py:1607] 2025-01-02 23:39:47,655 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:39:47,657 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4503] 2025-01-02 23:39:51,498 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:4511] 2025-01-02 23:39:51,498 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at saves/Qwen2VL-2B-Chat/full/train_qwen_vl.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:1013] 2025-01-02 23:39:51,503 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/generation_config.json\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:39:51,503 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.01,\n",
      "  \"top_k\": 1,\n",
      "  \"top_p\": 0.001\n",
      "}\n",
      "\n",
      "01/02/2025 23:39:51 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "01/02/2025 23:39:51 - INFO - llamafactory.model.loader - all params: 2,208,985,600\n",
      "01/02/2025 23:39:51 - WARNING - llamafactory.chat.hf_engine - There is no current event loop, creating a new one.\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:50:43,205 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:50:43,206 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"saves/Qwen2VL-2B-Chat/full/train_qwen_vl\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,207 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,207 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,207 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,207 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,207 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,207 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:50:43,373 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:50:43,374 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:373] 2025-01-02 23:50:43,374 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:429] 2025-01-02 23:50:43,374 >> Image processor Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,375 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,375 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,375 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,375 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,375 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2180] 2025-01-02 23:50:43,375 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2426] 2025-01-02 23:50:43,531 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|processing_utils.py:722] 2025-01-02 23:50:43,762 >> Processor Qwen2VLProcessor:\n",
      "- image_processor: Qwen2VLImageProcessor {\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"max_pixels\": 12845056,\n",
      "    \"min_pixels\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "- tokenizer: Qwen2TokenizerFast(name_or_path='saves/Qwen2VL-2B-Chat/full/train_qwen_vl', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "\n",
      "{\n",
      "  \"chat_template\": null,\n",
      "  \"processor_class\": \"Qwen2VLProcessor\"\n",
      "}\n",
      "\n",
      "01/02/2025 23:50:43 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
      "[INFO|configuration_utils.py:666] 2025-01-02 23:50:43,785 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/config.json\n",
      "[INFO|configuration_utils.py:735] 2025-01-02 23:50:43,786 >> Model config Qwen2VLConfig {\n",
      "  \"_name_or_path\": \"saves/Qwen2VL-2B-Chat/full/train_qwen_vl\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"type\": \"mrope\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0.dev0\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_chans\": 3,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"spatial_patch_size\": 14\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "01/02/2025 23:50:43 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n",
      "[INFO|modeling_utils.py:3671] 2025-01-02 23:50:43,786 >> loading weights file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/model.safetensors\n",
      "[INFO|modeling_utils.py:1607] 2025-01-02 23:50:43,801 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:50:43,803 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4503] 2025-01-02 23:50:45,319 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:4511] 2025-01-02 23:50:45,319 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at saves/Qwen2VL-2B-Chat/full/train_qwen_vl.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:1013] 2025-01-02 23:50:45,323 >> loading configuration file saves/Qwen2VL-2B-Chat/full/train_qwen_vl/generation_config.json\n",
      "[INFO|configuration_utils.py:1060] 2025-01-02 23:50:45,324 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.01,\n",
      "  \"top_k\": 1,\n",
      "  \"top_p\": 0.001\n",
      "}\n",
      "\n",
      "01/02/2025 23:50:45 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "01/02/2025 23:50:45 - INFO - llamafactory.model.loader - all params: 2,208,985,600\n",
      "01/02/2025 23:50:45 - WARNING - llamafactory.chat.hf_engine - There is no current event loop, creating a new one.\n"
     ]
    }
   ],
   "source": [
    "!USE_MODELSCOPE_HUB=1 llamafactory-cli webui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
